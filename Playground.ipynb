{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"data/tcga_brca_all_clean.csv.zip\"\n",
    "\n",
    "#TODO slide_id -> file path "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing genomic data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 4\n",
    "df = pd.read_csv(f,compression='zip')\n",
    "\n",
    "df_uncensored = (df[df[\"censorship\"]==0]).drop_duplicates([\"case_id\"])\n",
    "_,bins = pd.qcut(df_uncensored['survival_months'],q = n_bins,retbins=True)  # distribute censored survival months into quartiles\n",
    "\n",
    "# adapt bins \n",
    "bins[0] = 0 \n",
    "bins[-1] = np.inf\n",
    "#\n",
    "labels=[i for i in range(n_bins)]\n",
    "labels\n",
    "\n",
    "df.insert(6,\"survival_months_discretized\",  pd.cut(df[\"survival_months\"],\n",
    "                                                               bins=bins, \n",
    "                                                               labels=labels)) # insert binned survival momnth \n",
    "k = 7\n",
    "df.insert(3,\"kfold\",df.index%k) # insert kfold \n",
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale genomic data first and store in DF again\n",
    "then add labels to stratify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo add new column k-th-fold that contains an int in arange(k) where k is a cluster \n",
    "groundtruth = df[\"survival_months_discretized\"]\n",
    "censorship = df[\"censorship\"]\n",
    "genomics = df[df.keys()[11:]]\n",
    "genomics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_genomics = scaler.fit_transform(genomics)\n",
    "#scaler.inverse_transform(scaled_genomics)\n",
    "df_scaled = df.copy()\n",
    "df_scaled[df.keys()[11:]] = scaled_genomics\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  This leads to the full function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean2trainable(df_path,kfolds,n_bins=4,savename = None):\n",
    "    df = pd.read_csv(df_path,compression='zip')\n",
    "\n",
    "    # get time bins \n",
    "    df_uncensored = (df[df[\"censorship\"]==0]).drop_duplicates([\"case_id\"])\n",
    "    _,bins = pd.qcut(df_uncensored['survival_months'],q = n_bins,retbins=True)  # distribute censored survival months into quartiles\n",
    "\n",
    "    # adapt time bins \n",
    "    bins[0] = 0 \n",
    "    bins[-1] = np.inf\n",
    "    # bin name = index \n",
    "    labels = [i for i in range(n_bins)]\n",
    "    df.insert(6,\"survival_months_discretized\",  pd.cut(df[\"survival_months\"],\n",
    "                                                               bins=bins, \n",
    "                                                               labels=labels)) # insert binned survival month \n",
    "    diction = dict([(name,idx) for idx,name in enumerate(df[\"case_id\"].unique()) ])\n",
    "    df.insert(3,\"kfold\",df[\"case_id\"].map(diction)%kfolds) # insert kfold \n",
    "\n",
    "    genomics = df[df.keys()[11:]]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_genomics = scaler.fit_transform(genomics)\n",
    "    df[df.keys()[11:]] = scaled_genomics\n",
    "\n",
    "    if savename is not None:\n",
    "        df.to_csv(savename,index=False)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"data/tcga_brca_all_clean.csv.zip\"\n",
    "new_df = clean2trainable(f,5,4,savename = \"./data/tcga_brca_trainable.csv\")\n",
    "#new_df = clean2trainable(f,7,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_new = \"data/tcga_brca_trainable.csv\"\n",
    "df = pd.read_csv(f_new)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.keys()[11:]].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Fold crossvalidation\n",
    "1. Cluster dataset into k groups (shuffle first(seeded) then stratify by patient,split into equal chunks)\n",
    "2. use one group for testing and the others for training\n",
    "3. rotate such that each group is once used for testing\n",
    "4. use distribution of testing results to estimate real value \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7 \n",
    "a = np.arange(k) # df k-th fold \n",
    "for i in range(k):  \n",
    "    a = (a+1)%k\n",
    "    print(f\"train on {a[:-1]} test on {a[-1]}, store results in foldername: experiment1_fold{a[-1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"col1\": np.arange(100),\"col2\":np.random.rand(100)})\n",
    "df\n",
    "df[\"col1\"] = df[\"col1\"].apply(lambda x: f\"thisis{x}\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"data/tcga_brca_all_clean.csv.zip\"\n",
    "f = f.replace(\"all_clean.csv.zip\",\"trainable.csv\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchmetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "idx = torch.randint(low=0,high=4,size=(100,))\n",
    "values = torch.zeros(size=(100,4))\n",
    "source = torch.ones(size=(100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values.scatter_(dim=1,index=idx,src=source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth = torch.zeros(size=(10,4))\n",
    "a,b = groundtruth.size()\n",
    "labels = torch.randint(low=0,high=b,size=(1,a))\n",
    "groundtruth[torch.arange(a),labels]=1\n",
    "groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "acc = Accuracy(\"multiclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(low=0,high=2,size=(100,))\n",
    "a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "c = torch.randint(0,2,size=(100,))\n",
    "l = torch.randint(0,4,size=(100,))\n",
    "out = nn.Sigmoid()(torch.rand(size=(100,4)))\n",
    "c_index = concordance_index_censored(c,l,out)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "class Classifier_Head(nn.Module):\n",
    "    def __init__(self,outsize,d_hidden=256,t_bins=4):\n",
    "        super(Classifier_Head,self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(outsize,d_hidden)\n",
    "        torch.nn.init.kaiming_normal_(self.linear1.weight)\n",
    "        self.activ1 = nn.ReLU()\n",
    "        self.linear2  = nn.Linear(d_hidden,d_hidden)\n",
    "        torch.nn.init.kaiming_normal_(self.linear2.weight)\n",
    "        self.activ2 = nn.ReLU()\n",
    "        self.fc = nn.Linear(d_hidden,t_bins) # TODO test add layer\n",
    "    def forward(self,x):\n",
    "        x = torch.flatten(x,start_dim=1)\n",
    "        x = self.activ1(self.linear1(x))\n",
    "        x = self.activ2(self.linear2(x))\n",
    "        return self.fc(x)\n",
    "\n",
    "class Attention_surv(nn.Module):\n",
    "    def __init__(self,hist_dim,bins):\n",
    "        super(Attention_surv,self).__init__()\n",
    "        self.mhsa = nn.MultiheadAttention(hist_dim,num_heads=4,dropout=0.3,batch_first=True)\n",
    "        self.head = Classifier_Head(hist_dim,t_bins = bins)\n",
    "    def forward(self,hist):\n",
    "        attn_output, attn_output_weights = self.mhsa(hist,hist,hist)\n",
    "        attn_output = attn_output.mean(dim=1)\n",
    "        return self.head(attn_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi_modal_ds import HistGen_Dataset\n",
    "import pandas as pd\n",
    "from utils import Survival_Loss\n",
    "alpha = 0.25\n",
    "bins = 4\n",
    "lr = 2e-4\n",
    "l1_lambda = 1e-5\n",
    "\n",
    "f = f\"/nodes/bevog/work4/seibel/data/tcga_brca_trainable{bins}.csv\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "data_path = \"/nodes/bevog/work4/seibel/data/TCGA-BRCA-DX-features/tcga_brca_20x_features/pt_files\" # folderpath for h5y fiels which contain the WSI feat vecs \n",
    "batchsize = 1  # due to different size of bags \n",
    "\n",
    "df = pd.read_csv(f)\n",
    "train_ds = HistGen_Dataset(df,data_path = data_path,train=True)\n",
    "test_ds = HistGen_Dataset(df,data_path = data_path,train=False)\n",
    "training_dataloader = torch.utils.data.DataLoader( train_ds,batch_size=batchsize)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_ds,batch_size=batchsize)\n",
    "\n",
    "\n",
    "model = Attention_surv(hist_dim=2048,bins=bins).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr,betas=[0.9,0.999],weight_decay=1e-5,)\n",
    "criterion = Survival_Loss(alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,(histo,gen,c,l,_) in enumerate(training_dataloader):\n",
    "    histo = histo.to(device)\n",
    "    out = model(histo)\n",
    "    out = out.cpu()\n",
    "    #weights = model.mhsa.parameters()\n",
    "    loss = criterion(out,c,l) #+ l1_lambda * torch.norm(weights.cpu(),1)\n",
    "    loss.backward()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KaplanMeier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "bins = 4\n",
    "f = f\"/nodes/bevog/work4/seibel/data/tcga_brca_trainable{bins}.csv\"\n",
    "df = pd.read_csv(f)\n",
    "df = df[[\"slide_id\",\"survival_months_discretized\",\"censorship\",\"survival_months\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(kaplan_meier_estimator)\n",
    "event = np.asarray(1-df[\"censorship\"]).astype(bool)\n",
    "time_exit = np.asarray(df[\"survival_months\"])\n",
    "\n",
    "\n",
    "x_full, y_full = kaplan_meier_estimator(event, time_exit)\n",
    "plt.step(x_full, y_full, where=\"post\")\n",
    "plt.ylim(0, 1.1)\n",
    "plt.grid()\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import AttMil_Survival\n",
    "from multi_modal_ds import HistGen_Dataset\n",
    "import torch \n",
    "from torch import nn \n",
    "from utils import c_index\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#load model \n",
    "d_hist = 2048\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "bins = 4\n",
    "model = AttMil_Survival(d_hist,bins,device ).to(device)\n",
    "#load weights \n",
    "f_weights = \"/work4/seibel/results/alpha0.5hist/AttMil_Survival_nll-alpha0.5-fold5-l1_lambda1e-07.pth\"\n",
    "weights = torch.load(f_weights)['model']\n",
    "model.load_state_dict(weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f =  f\"/nodes/bevog/work4/seibel/data/tcga_brca_trainable{bins}.csv\"\n",
    "df = pd.read_csv(f)\n",
    "data_path = \"/nodes/bevog/work4/seibel/data/TCGA-BRCA-DX-features/tcga_brca_20x_features/pt_files\" \n",
    "test_ds = HistGen_Dataset(df,data_path,train=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_ds,batch_size=1)\n",
    "\n",
    "out_all_val =torch.empty(size=(len(test_dataloader),bins),device='cpu')        \n",
    "l_all_val = torch.empty(size=(len(test_dataloader),),device='cpu').to(torch.int16)\n",
    "l_cont_all_val = torch.empty(size=(len(test_dataloader),),device='cpu').to(torch.int16)\n",
    "c_all_val = torch.empty(size=(len(test_dataloader),),device='cpu').to(torch.int16)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for  idx,(histo,gen,c,l,l_cont) in enumerate(test_dataloader):\n",
    "        x = histo.to(device)\n",
    "        out = model(x)\n",
    "        out = out.cpu()\n",
    "        \n",
    "        out_all_val[idx,:] = out\n",
    "        l_all_val[idx] = l\n",
    "        c_all_val[idx] = c\n",
    "        l_cont_all_val[idx] = l_cont\n",
    "\n",
    "h = nn.Sigmoid()(out_all_val)\n",
    "S = torch.cumprod(1-h,dim = -1)\n",
    "risk = -S.sum(dim=1) ## TODO why is it not 1-S ???\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import c_index\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "c_ind = c_index(out_all_val,c_all_val,l_all_val)\n",
    "plt.title(f\"risk distribution with c_index= {round(c_ind,3)}\")\n",
    "plt.hist(risk.numpy(),bins = 100)\n",
    "plt.show()\n",
    "test_ds.gen_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 4 \n",
    "eps=0.1\n",
    "threshold = np.linspace(risk.min()+eps,risk.max()-eps,num=12)\n",
    "fig,ax1 = plt.subplots(rows,len(threshold)//rows,figsize=(24,8))\n",
    "fig.tight_layout()\n",
    "for i in range(len(threshold)):\n",
    "    risk_bool = risk>threshold[i]\n",
    "    event1 = np.asarray(1-c_all_val[risk_bool]).astype(bool)\n",
    "    time_exit1 = np.asarray(l_cont_all_val[risk_bool])\n",
    "    x1, y1 = kaplan_meier_estimator(event1, time_exit1)\n",
    "\n",
    "    event2 = np.asarray(1-c_all_val[~risk_bool]).astype(bool)\n",
    "    time_exit2 = np.asarray(l_cont_all_val[~risk_bool])\n",
    "    x2, y2 = kaplan_meier_estimator(event2, time_exit2)\n",
    "    \n",
    "    x_full, y_full = kaplan_meier_estimator(event, time_exit)\n",
    "\n",
    "    ax1.flatten()[i].set_title(f\"KM for threshold {round(threshold[i],3)}\")\n",
    "    ax1.flatten()[i].step(x1, y1, where=\"post\",label=\"high risk\")\n",
    "    ax1.flatten()[i].step(x2, y2, where=\"post\",label=\"low risk\")\n",
    "    ax1.flatten()[i].step(x_full, y_full, where=\"post\",label=\"full KM\")\n",
    "    \n",
    "    ax1.flatten()[i].set_ylim(0, 1.1)\n",
    "    ax1.flatten()[i].grid()\n",
    "    ax1.flatten()[i].legend()\n",
    "\n",
    "\n",
    "#plt.clf\n",
    "#plt.title(f\"KM for threshold {round(threshold[i])}\")\n",
    "#plt.step(x1, y1, where=\"post\",label=\"high risk\")\n",
    "#plt.step(x2, y2, where=\"post\",label=\"low risk\")\n",
    "#plt.ylim(0, 1.1)\n",
    "#plt.grid()\n",
    "#plt.legend()\n",
    "#plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Scatter risk vs survival month\")\n",
    "plt.scatter(risk[c_all_val.type(torch.bool)],l_cont_all_val[c_all_val.type(torch.bool)],s = 4,label=\"censored\")\n",
    "plt.scatter(risk[~(c_all_val.type(torch.bool))],l_cont_all_val[~(c_all_val.type(torch.bool))],s = 4,label=\"uncensored\")\n",
    "plt.xlabel(\"Risk score\")\n",
    "plt.ylabel(\"Survival month\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.title(f\"risk distribution\")\n",
    "plt.hist(risk[c_all_val.type(torch.bool)].numpy(),bins = 30,alpha=0.5,label=\"a\")\n",
    "plt.hist(risk[~(c_all_val.type(torch.bool))].numpy(),bins = 30,alpha=0.5,label=\"b\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import matplotlib.pyplot as plt \n",
    "wandb.init(project=\"MultiModal\",entity=\"tobias-seibel\",name=\"tests\")\n",
    "out_all_val = out_all_val\n",
    "n_thresholds = 4\n",
    "nbins = 30\n",
    "c_all_val = c_all_val\n",
    "l_cont_all_val = l_cont_all_val \n",
    "\n",
    "#risk\n",
    "def get_risk(out):\n",
    "    h = nn.Sigmoid()(out)\n",
    "    S = torch.cumprod(1-h,dim = -1)\n",
    "    risk = -S.sum(dim=1)\n",
    "    return risk\n",
    "risk_all = get_risk(out_all_val)\n",
    "\n",
    "#thresholds\n",
    "min,max = risk_all.min(),risk_all.max()\n",
    "thresholds = torch.linspace(min,max,n_thresholds+2)[1:-1]\n",
    "\n",
    "#hist \n",
    "censored = c_all_val.type(torch.bool)\n",
    "uncensored = ~c_all_val.type(torch.bool)\n",
    "\n",
    "x_c1 = torch.histc(risk_all[censored],bins=nbins,min = min , max =max ) \n",
    "x1_label = torch.ones_like(x_c1)\n",
    "x_c2 = torch.histc(risk_all[uncensored],bins=nbins,min = min , max =max ) \n",
    "x2_label = torch.zeros_like(x_c2)\n",
    "x_all = torch.stack((x_c1,x_c2)).T\n",
    "\n",
    "\n",
    "#table = wandb.Table(data = x_all.tolist(),columns=[\"censored\",\"uncensored\"])\n",
    "table = wandb.plot.line_series(\n",
    "          xs =np.linspace(min,max,nbins),\n",
    "          ys=[x_c1,x_c2],\n",
    "          keys=[\"censored\", \"uncensored\"],\n",
    "          title=f\"Histogramm\",\n",
    "          xname=\"risk\")\n",
    "wandb.log({\"custom\":table})\n",
    "#KM\n",
    "\n",
    "#stepfunction\n",
    "def stepfunc(x,y,eps=1e-4):\n",
    "    x = np.stack((x-eps,x),axis=1).flatten()\n",
    "    y = np.stack((y,y),axis=1).flatten()\n",
    "    return x[1:].copy(),y[:-1].copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for idx,threshold in enumerate(thresholds.tolist()): #thresholds\n",
    "    x_full, y_full = kaplan_meier_estimator(uncensored.numpy(), l_cont_all_val)\n",
    "\n",
    "    xlow, ylow = kaplan_meier_estimator(uncensored[risk>threshold].numpy(),\n",
    "                                l_cont_all_val[risk>threshold].numpy())\n",
    "\n",
    "    xhigh, yhigh = kaplan_meier_estimator(uncensored[risk<=threshold].numpy(),\n",
    "                                l_cont_all_val[risk<=threshold].numpy())\n",
    "    \n",
    "    xfull, yfull = stepfunc(x_full, y_full)\n",
    "    xlow, ylow =stepfunc(xlow, ylow)\n",
    "    xhigh, yhigh =stepfunc(xhigh, yhigh)\n",
    "\n",
    "    #x,y1,y2,y3 = KM_table(xlow,ylow,xhigh,yhigh,xfull,yfull,)\n",
    "    lineseries = wandb.plot.line_series(\n",
    "          xs=[xlow,xhigh,xfull],\n",
    "          ys=[ylow,yhigh,yfull],\n",
    "          keys=[\"lowrisk\", \"highrisk\",\"fullrisk\"],\n",
    "          title=f\"KM Stratification at risk={str(round(threshold,2)).replace('.',',')}\",\n",
    "          xname=\"time\")\n",
    "    \n",
    "    wandb.log({f\"KM_{idx}\" :lineseries})\n",
    "    \n",
    "\n",
    "# Log the table to wandb\n",
    "wandb.log({\"line_series\": table})\n",
    "\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def KM_table(xlow,ylow,xhigh,yhigh,xfull,yfull,):\n",
    "    ### get KM curve on same x values... not needed anymore FML\n",
    "    low_all = np.stack((xlow,ylow,np.empty_like(ylow)*np.nan,np.empty_like(ylow)*np.nan),1)\n",
    "    high_all = np.stack((xhigh,np.empty_like(yhigh)*np.nan,yhigh,np.empty_like(yhigh)*np.nan),1)\n",
    "    full_all = np.stack((xfull,np.empty_like(yfull)*np.nan,np.empty_like(yfull)*np.nan, yfull),1)\n",
    "    all = np.concatenate((low_all,high_all,full_all),axis=0)\n",
    "\n",
    "    all = all[all[:, 0].argsort()] # sort by first element \n",
    "\n",
    "    for i in range(1,len(all)):\n",
    "        a = all[i-1,1:] # =:prev-line\n",
    "        b = all[i,1:]  # =:line\n",
    "        all[i,1:] = np.where(np.isnan(b),a,b)\n",
    "        if all[i,0]==all[i-1,0]: #if on same x give info to line, set x of prev-line to nan\n",
    "            all[i-1,0] = np.nan\n",
    "            \n",
    "    all = all[all[:, 0].argsort()]\n",
    "    all = all[~np.isnan(all[:,0])]\n",
    "    return all[:,0],all[:,1],all[:,2],all[:,3]  # x, y_low,y_high,y_full\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final FUnctions for Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def KM_wandb(run,out,c,event_cond,n_thresholds = 4,nbins = 30):\n",
    "    print(\"Start Logging KM-Estimators\")\n",
    "    risk = get_risk(out)\n",
    "    \n",
    "    #thresholds\n",
    "    min,max = risk.min(),risk.max()\n",
    "    thresholds = np.linspace(min,max,n_thresholds+2)[1:-1]\n",
    "    \n",
    "    #hist\n",
    "    censored = c.type(torch.bool)\n",
    "    uncensored = ~c.type(torch.bool)\n",
    "    \n",
    "    hist_censored = torch.histc(risk[censored],bins=nbins,min = min , max =max ) \n",
    "    hist_uncensored = torch.histc(risk[uncensored],bins=nbins,min = min , max =max ) \n",
    "    \n",
    "    table = run.plot.line_series(\n",
    "          xs =np.linspace(min,max,nbins),\n",
    "          ys=[hist_censored,hist_uncensored],\n",
    "          keys=[\"censored\", \"uncensored\"],\n",
    "          title=f\"Histogramm\",\n",
    "          xname=\"risk\")\n",
    "    run.log({\"risk_histogramm\":table})\n",
    "    \n",
    "    #KaplanMeier Plots\n",
    "    x_full, y_full = kaplan_meier_estimator(uncensored.numpy(), event_cond)\n",
    "    xfull, yfull = stepfunc(x_full, y_full)\n",
    "    for idx,threshold in enumerate(thresholds): \n",
    "        xlow, ylow = kaplan_meier_estimator(uncensored[risk>threshold].numpy(),\n",
    "                                    event_cond[risk>threshold])\n",
    "\n",
    "        xhigh, yhigh = kaplan_meier_estimator(uncensored[risk<=threshold].numpy(),\n",
    "                                    event_cond[risk<=threshold])\n",
    "        \n",
    "        xlow, ylow =stepfunc(xlow, ylow)\n",
    "        xhigh, yhigh =stepfunc(xhigh, yhigh)\n",
    "\n",
    "        \n",
    "        lineseries = run.plot.line_series(\n",
    "            xs=[xlow,xhigh,xfull],\n",
    "            ys=[ylow,yhigh,yfull],\n",
    "            keys=[\"lowrisk\", \"highrisk\",\"fullrisk\"],\n",
    "            title=f\"KM Stratification at risk={str(round(threshold,2)).replace('.',',')}\",\n",
    "            xname=\"time\")\n",
    "        \n",
    "        run.log({f\"KM_{idx}\" :lineseries})\n",
    "    print(\"Finished logging KM-Estimators\")\n",
    "    \n",
    "def get_risk(out):\n",
    "    h = nn.Sigmoid()(out)\n",
    "    S = torch.cumprod(1-h,dim = -1)\n",
    "    risk = -S.sum(dim=1)\n",
    "    return risk\n",
    "\n",
    "def stepfunc(x,y,eps=1e-4):\n",
    "    x = np.stack((x-eps,x),axis=1).flatten()\n",
    "    y = np.stack((y,y),axis=1).flatten()\n",
    "    return x[1:],y[:-1]\n",
    "\n",
    "def do_table(x,y,label):\n",
    "    return [[x[i],y[i],label] for i in range(len(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import matplotlib.pyplot as plt \n",
    "wandb.init(project=\"MultiModal\",entity=\"tobias-seibel\",name=\"tests\")\n",
    "out_all_val = out_all_val\n",
    "n_thresholds = 4\n",
    "nbins = 30\n",
    "c_all_val = c_all_val\n",
    "l_cont_all_val = l_cont_all_val \n",
    "\n",
    "#risk\n",
    "def get_risk(out):\n",
    "    h = nn.Sigmoid()(out)\n",
    "    S = torch.cumprod(1-h,dim = -1)\n",
    "    risk = -S.sum(dim=1)\n",
    "    return risk\n",
    "risk_all = get_risk(out_all_val)\n",
    "\n",
    "#thresholds\n",
    "min,max = risk_all.min(),risk_all.max()\n",
    "thresholds = torch.linspace(min,max,n_thresholds+2)[1:-1]\n",
    "\n",
    "#hist \n",
    "censored = c_all_val.type(torch.bool)\n",
    "uncensored = ~c_all_val.type(torch.bool)\n",
    "\n",
    "x_c1 = torch.histc(risk_all[censored],bins=nbins,min = min , max =max ).numpy()\n",
    "x1_label = np.chararray(np.shape(x_c1))\n",
    "x1_label[:]=\"censored\"\n",
    "x_c2 = torch.histc(risk_all[uncensored],bins=nbins,min = min , max =max ).numpy() \n",
    "x2_label = np.chararray(np.shape(x_c2))\n",
    "x2_label[:]=\"uncensored\"\n",
    "\n",
    "x1 = np.stack((np.linspace(min,max,nbins),x_c1,x1_label))\n",
    "x2 = np.stack((np.linspace(min,max,nbins),x_c2,x2_label))\n",
    "np.concatenate((x1,x2),dim=1).T\n",
    "\n",
    "table = wandb.Table(\n",
    "          data = np.concatenate((x1,x2),dim=1).T,\n",
    "          columns=[\"bins\", \"risk\",\"category\"],\n",
    "          \n",
    "          \n",
    "\n",
    "          )\n",
    "wandb.log({\"custom\":table})\n",
    "#KM\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better version for custom plots! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.linspace(min,max,nbins)\n",
    "x_c1 = torch.histc(risk_all[censored],bins=nbins,min = min , max =max ).numpy()\n",
    "x_c2 = torch.histc(risk_all[uncensored],bins=nbins,min = min , max =max ).numpy() \n",
    "\n",
    "table_hist = wandb.Table(\n",
    "          data = do_table(x,x_c1,\"censored\")+do_table(x,x_c2,\"uncensored\"),\n",
    "          columns=[\"risk\", \"count\",\"category\"],\n",
    "          )\n",
    "\n",
    "fields_hist = {\"x\":\"risk\",\"y\":\"count\",\"groupKeys\":\"category\",\"title\":\"Risk Distribution\"}\n",
    "custom_histogram = wandb.plot_table(vega_spec_name=\"tobias-seibel/risk_distribution\",\n",
    "              data_table=table_hist,\n",
    "              fields = fields_hist )\n",
    "              \n",
    "              \n",
    "event_cond = l_cont_all_val\n",
    "threshold = -2\n",
    "xfull, yfull = kaplan_meier_estimator(uncensored.numpy(), event_cond)\n",
    "\n",
    "xlow, ylow = kaplan_meier_estimator(uncensored[risk>threshold].numpy(),\n",
    "                                    event_cond[risk>threshold])\n",
    "\n",
    "xhigh, yhigh = kaplan_meier_estimator(uncensored[risk<=threshold].numpy(),\n",
    "                                    event_cond[risk<=threshold])\n",
    "        \n",
    "\n",
    "\n",
    "table_KM = wandb.Table(\n",
    "          data = do_table(xlow,ylow,\"low risk group\")+do_table(xhigh,yhigh,\"risk high group\")+do_table(xfull,yfull,\"total group\"),\n",
    "          columns=[\"time\",\"Survival Probability\",\"Group\"],)\n",
    "\n",
    "field_KM = {\"x\":\"time\",\"y\":\"Survival Probability\",\"groupKeys\":\"Group\"}\n",
    "custom_KM = wandb.plot_table(vega_spec_name=\"tobias-seibel/kaplanmeier\",\n",
    "              data_table=table_KM,\n",
    "              fields = field_KM, \n",
    "              string_fields={\"title\":f\"KM Risk Stratification at {round(threshold,2)}\"},\n",
    "              )\n",
    "\n",
    "wandb.init()\n",
    "\n",
    "idx = 1 \n",
    "wandb.log({\"Risk Distribution\":custom_histogram,\"KM{idx}\":custom_KM}) #tobias-seibel/risk_distribution # tobias-seibel/kaplanmeier\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KM_wandb(run,out,c,event_cond,n_thresholds = 4,nbins = 30):\n",
    "    print(\"Start Logging KM-Estimators\")\n",
    "    risk = get_risk(out)\n",
    "    \n",
    "    #thresholds\n",
    "    min,max = risk.min(),risk.max()\n",
    "    thresholds = np.linspace(min,max,n_thresholds+2)[1:-1]\n",
    "    \n",
    "    #hist\n",
    "    censored = c.type(torch.bool)\n",
    "    uncensored = ~c.type(torch.bool)\n",
    "    \n",
    "    ###wandb histogram\n",
    "    x = np.linspace(min,max,nbins)\n",
    "    x_c1 = torch.histc(risk_all[censored],bins=nbins,min = min , max =max ).numpy()\n",
    "    x_c2 = torch.histc(risk_all[uncensored],bins=nbins,min = min , max =max ).numpy() \n",
    "\n",
    "    table_hist = wandb.Table(\n",
    "            data = do_table(x,x_c1,\"censored\")+do_table(x,x_c2,\"uncensored\"),\n",
    "            columns=[\"risk\", \"count\",\"category\"],\n",
    "            )\n",
    "\n",
    "    fields_hist = {\"x\":\"risk\",\"y\":\"count\",\"groupKeys\":\"category\",\"title\":\"Risk Distribution\"}\n",
    "    custom_histogram = wandb.plot_table(vega_spec_name=\"tobias-seibel/risk_distribution\",\n",
    "                data_table=table_hist,\n",
    "                fields = fields_hist )\n",
    "    \n",
    "    wandb.log({\"Risk Distribution\":custom_histogram})\n",
    "    ###\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #KaplanMeier Plots\n",
    "    xfull, yfull = kaplan_meier_estimator(uncensored.numpy(), event_cond)\n",
    "    \n",
    "    for idx,threshold in enumerate(thresholds): \n",
    "        xlow, ylow = kaplan_meier_estimator(uncensored[risk>threshold].numpy(),\n",
    "                                    event_cond[risk>threshold])\n",
    "\n",
    "        xhigh, yhigh = kaplan_meier_estimator(uncensored[risk<=threshold].numpy(),\n",
    "                                    event_cond[risk<=threshold])\n",
    "        \n",
    "        \n",
    "        table_KM = wandb.Table(data = do_table(xlow,ylow,\"low risk group\")+do_table(xhigh,yhigh,\"risk high group\")+do_table(xfull,yfull,\"total group\"),\n",
    "                        columns=[\"time\",\"Survival Probability\",\"Group\"],)\n",
    "\n",
    "        field_KM = {\"x\":\"time\",\"y\":\"Survival Probability\",\"groupKeys\":\"Group\"}\n",
    "        custom_KM = wandb.plot_table(vega_spec_name=\"tobias-seibel/kaplanmeier\",\n",
    "                    data_table=table_KM,\n",
    "                    fields = field_KM, \n",
    "                    string_fields={\"title\":f\"KM Risk Stratification at {round(threshold,2)}\"},\n",
    "                    )\n",
    "        run.log({f\"KM_{idx}\" :custom_KM})\n",
    "    print(\"Finished logging KM-Estimators\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init()\n",
    "KM_wandb(run,out_all_val,c_all_val,l_cont_all_val,n_thresholds = 4,nbins = 30)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from utils import *\n",
    "class Classifier_Head(nn.Module):\n",
    "    def __init__(self,outsize,d_hidden=256,t_bins=4):\n",
    "        super(Classifier_Head,self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(outsize,d_hidden)\n",
    "        torch.nn.init.kaiming_normal_(self.linear1.weight)\n",
    "        self.activ1 = nn.ReLU()\n",
    "        self.linear2  = nn.Linear(d_hidden,d_hidden)\n",
    "        torch.nn.init.kaiming_normal_(self.linear2.weight)\n",
    "        self.activ2 = nn.ReLU()\n",
    "        self.fc = nn.Linear(d_hidden,t_bins) # TODO test add layer\n",
    "    def forward(self,x):\n",
    "        x = torch.flatten(x,start_dim=1)\n",
    "        x = self.activ1(self.linear1(x))\n",
    "        x = self.activ2(self.linear2(x))\n",
    "        return self.fc(x)\n",
    "    \n",
    "    \n",
    "class TransformerMil_Survival(nn.Module):\n",
    "  def __init__(self,d_seq,d_transformer,bins):\n",
    "    super(TransformerMil_Survival,self).__init__()\n",
    "    d_out = d_hidden = 256\n",
    "    self.lin_embedder1 = nn.Linear(d_seq,d_transformer,dropout)\n",
    "    #self.Encoder = torch.nn.TransformerEncoder(nn.TransformerEncoderLayer(d_transformer,\n",
    "    #                                                                 nhead=2,dropout=0.1,activation=nn.GELU(),batch_first=True)\n",
    "    #                                      ,num_layers=2)\n",
    "    self.Encoder=nn.TransformerEncoderLayer(d_transformer,nhead=2,dropout=dropout,activation=nn.GELU(),batch_first=True)\n",
    "    self.lin_embedder2 = nn.Linear(d_transformer,d_out)\n",
    "    self.Classifier_Head = Classifier_Head(outsize = d_out,d_hidden=d_hidden,t_bins=bins)\n",
    "  def forward(self,x):\n",
    "    \n",
    "    x = self.lin_embedder1(x)\n",
    "    x = self.Encoder(x)\n",
    "    out = x.mean(dim=-2)\n",
    "    out = self.lin_embedder2(out)\n",
    "    return self.Classifier_Head(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "bins = 4\n",
    "model = TransformerMil_Survival(d_seq=2048,d_transformer=1024,bins=bins)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "criterion = Survival_Loss(0.25) \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.00003,betas=[0.9,0.999],weight_decay=1e-5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nseq = 15000\n",
    "B=1\n",
    "dims = 2048\n",
    "\n",
    "x = torch.rand(size=(B,nseq,dims)).to(device)\n",
    "l = torch.randint(low=0, high=bins, size=(B,)).to(device)\n",
    "c = torch.randint(low=0, high=2, size=(B,)).to(device)  ## Groundtruth boolean information wether the the patient is censored  c = 1 or uncensored  \n",
    "\n",
    "out = model(x)\n",
    "loss = criterion(out,c,l)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np \n",
    "kfold=5\n",
    "names = df[\"case_id\"].unique()\n",
    "\n",
    "diction = dict([(name,idx) for idx,name in enumerate(df[\"case_id\"].unique()) ])\n",
    "df[\"kfold\"] = df[\"case_id\"].map(diction)%kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"kfold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.empty(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check lossfunction behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Aggregation_Utils import Survival_Loss\n",
    "import torch\n",
    "lossfunc = Survival_Loss(alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 4*(torch.rand((1,4))+torch.tensor([0,0,0,3]))\n",
    "linlayer = torch.nn.Linear(4,4)\n",
    "c = torch.tensor([1])\n",
    "t = torch.tensor([3])\n",
    "linlayer.zero_grad()\n",
    "loss = lossfunc(linlayer(out),c,t)\n",
    "loss.backward()\n",
    "\n",
    "for name,param in linlayer.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(f\"Parameter: {name}, Gradient: {list(param.grad.flatten().numpy())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.Aggregation_Utils import Survival_Loss\n",
    "def improvedout(out,c,t,alpha,fac,tanapproach=False):\n",
    "    lossfunc = Survival_Loss(alpha=alpha)\n",
    "    optimizer = torch.optim.AdamW([out],lr=0.01)\n",
    "    loss_vec = []\n",
    "    for i in range(1000):\n",
    "        optimizer.zero_grad()\n",
    "        if tanapproach:\n",
    "            x = torch.arange(out.size(-1)).unsqueeze(0).repeat(out.size(0),1)\n",
    "            target = torch.tanh(x-t.unsqueeze(1))-alpha*c.unsqueeze(-1).repeat(1,x.size(-1))\n",
    "            loss = torch.nn.MSELoss()(out,target)\n",
    "        else:\n",
    "            loss = lossfunc(out,c,t)\n",
    "        loss_vec.append(loss.detach().item())\n",
    "        \n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "    return out ,loss_vec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 8\n",
    "alpha=0.5\n",
    "n_censored = 20\n",
    "n_uncensored = 2\n",
    "    \n",
    "loss_vec_all = []\n",
    "risks_list = []\n",
    "outvals = []\n",
    "for i in range(bins):\n",
    "    \n",
    "    randi= torch.cat((0.01+torch.rand((n_censored,bins)),torch.rand((n_uncensored,bins))),dim=0)\n",
    "    out = (randi.clone().detach()).requires_grad_(True)\n",
    "    #out = torch.cumsum(out,dim=1).requires_grad_(True)\n",
    "    c = torch.tensor([item for sublist in [[0]*n_uncensored,[1]*n_censored] for item in sublist])\n",
    "    t = torch.tensor([item for sublist in [[i]*n_uncensored,[i]*n_censored] for item in sublist])\n",
    "    outputval,loss_vec = improvedout(out,c,t,alpha,fac=i,tanapproach=True)\n",
    "    loss_vec_all.append(loss_vec)\n",
    "    h = torch.nn.Sigmoid()(outputval)\n",
    "    S = torch.cumprod(1-h,dim = -1)\n",
    "    #risk = torch.exp(-S.sum(dim=1))\n",
    "    risk = -S.sum(dim=1)\n",
    "    risks_list.append(risk.detach().numpy())\n",
    "    outvals.append(outputval.detach().numpy())\n",
    "    #print(\"i :\",i,\"risk :\",risk.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "for j in range(len(loss_vec_all)):\n",
    "    plt.plot(loss_vec_all[j],label=str(j))\n",
    "plt.legend()\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"loss\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "for j in range(len(loss_vec_all)):\n",
    "    plt.plot(loss_vec_all[j],label=str(j))\n",
    "plt.legend()\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"loss\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "for j in range(n_censored+n_uncensored):\n",
    "    plt.plot([risks[j] for risks in risks_list],color=f\"green\" if j<n_censored else f\"red\",linewidth=0.1)\n",
    "plt.xlabel(\"targetbin\")\n",
    "plt.ylabel(\"riskvalue\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0]*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = torch.tensor(np.array(outvals)) # target, n_censored+n_uncensored, bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "for i in range(bins):\n",
    "    for j in range(n_censored+n_uncensored):\n",
    "        label = \"uncensored\" if j<n_censored else \"censored\"\n",
    "        col = \"red\" if j<n_censored else \"blue\"\n",
    "        #col = \"red\" if i==0 else \"green\" if i==1 else \"yellow\" if i==2 else \"blue\"\n",
    "        plt.plot(a[i,j,:],linewidth=0.1,color=col)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import torch\n",
    "path = \"/nodes/bevog/work4/seibel/data/TCGA-BRCA-DX-features/vit_mae_tiny_I1K_PT_TCGA_BRCA_FT_HIST_GEN_119eps_features/pt_files\"\n",
    "#path = \"/nodes/bevog/work4/seibel/data/TCGA-BRCA-DX-features/vit_mae_tiny_I1K_PT_FT_50eps_TCGA_BRCA_features/pt_files\"\n",
    "#path = \"/nodes/bevog/work4/seibel/data/TCGA-BRCA-DX-features/vit_mae_tiny_I1K_PT_FT_50eps_TCGA_BRCA_features/pt_files\"\n",
    "names = os.listdir(path)\n",
    "tensors= []\n",
    "for i in range(len(names)):\n",
    "    tensor_path =os.path.join(path, names[i]) \n",
    "    tensor_file =h5py.File(tensor_path, \"r\")\n",
    "    tensor_file = torch.tensor(tensor_file[\"feats\"][:]).to(torch.float32)\n",
    "    tensors.append(tensor_file)\n",
    "    \n",
    "tensors = torch.cat(tensors)\n",
    "tensors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors.isnan().any().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors[:][192:].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import  pytorch_lightning as pl\n",
    "from utils.Encoder_Utils import Patient_Tileset\n",
    "from torchvision import transforms\n",
    "from models.Encoder_Models import SupViTSurv\n",
    "mycheckpnt = \"/home/seibel/maetiny_ft200eps_brca_histo_gen_cont/epoch=119-step=217080_mycopy.ckpt\"\n",
    "model = SupViTSurv(lr=0.001,nbins=4,alpha=0.25)\n",
    "model.load_state_dict(torch.load(mycheckpnt)[\"state_dict\"])\n",
    "df_data_path = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_trainsplit.csv\"\n",
    "df_tile_slide_path = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/DF_TCGA-BRCA-TIILES-NORM.csv\"\n",
    "df_tile_paths = pd.read_csv(df_tile_slide_path) \n",
    "\n",
    "transform = transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                            transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5)),\n",
    "                                            ]\n",
    "                                        )\n",
    "slide_name = \"TCGA-A2-A3XW-01Z-00-DX1.45F5F36F-5503-4A38-AF37-E526915A8DBE.svs\"\n",
    "idx = 104\n",
    "df_trainset = pd.read_csv(df_data_path)\n",
    "\n",
    "genomics_tensor = torch.Tensor(df_trainset[df_trainset.keys()[11:]].to_numpy()).to(torch.float32)\n",
    "batch_size=128\n",
    "num_workers=1\n",
    "pin_memory=False\n",
    "trainer = pl.Trainer(\n",
    "        precision=\"16-mixed\",\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        detect_anomaly=True\n",
    "           )\n",
    "df_tiles = df_tile_paths[df_tile_paths[\"slide_id\"]==slide_name]\n",
    "gen_vec = genomics_tensor[idx]\n",
    "dataload_i = DataLoader(Patient_Tileset(df_tiles[\"tilepath\"],gen_vec,transform), batch_size=batch_size,num_workers=num_workers,pin_memory=pin_memory)\n",
    "#predictions = trainer.predict(model,dataload_i)\n",
    "#feats = torch.cat(predictions,dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "model.eval()\n",
    "for idx,batch  in enumerate(dataload_i):\n",
    "    x,y = batch \n",
    "    with torch.no_grad():\n",
    "        output = model.predict_step(batch,idx)\n",
    "        outputs.append(output)\n",
    "outputs = torch.cat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = trainer.predict(model,dataload_i)\n",
    "outputs = torch.cat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,params in model.named_parameters():\n",
    "    if params.isnan().any().item():\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Aggregation_Models import SNN_Survival\n",
    "from datasets.Aggregation_DS import Gen_Dataset\n",
    "import os \n",
    "import torch \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "bins = 4\n",
    "epochs = 40 \n",
    "device ='cuda' if  torch.cuda.is_available() else 'cpu'\n",
    "storepath = None\n",
    "run_name = \"name\"\n",
    "batchsize = 32\n",
    "d_gen_out = 32\n",
    "feature_path = \"/nodes/bevog/work4/seibel/data/TCGA-BRCA-DX-features/vit_mae_tiny_I1K_PT_FT_50eps_TCGA_BRCA_features/pt_files\"\n",
    "num_workers = 1\n",
    "csv_path_train = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_trainsplit.csv\"\n",
    "csv_path_test = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_testsplit.csv\"\n",
    "csv_path_val = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_valsplit.csv\"\n",
    "\n",
    "df_train = pd.read_csv(csv_path_train)\n",
    "df_test = pd.read_csv(csv_path_test)\n",
    "df_val = pd.read_csv(csv_path_val)\n",
    "\n",
    "train_ds = Gen_Dataset(df_train,data_path = feature_path,mode=\"train\")\n",
    "val_ds = Gen_Dataset(df_val,data_path = feature_path,mode=\"val\")\n",
    "test_ds = Gen_Dataset(df_test,data_path = feature_path,mode=\"test\")\n",
    "\n",
    "d_gen = train_ds.gen_depth()\n",
    "\n",
    "model = SNN_Survival(d_gen,d_gen_out,bins,device,activation=\"SELU\").to(device)\n",
    "training_dataloader = torch.utils.data.DataLoader( train_ds,batch_size=batchsize,num_workers=num_workers,pin_memory=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_ds,batch_size=batchsize,num_workers=num_workers,pin_memory=False)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_ds,batch_size=batchsize,num_workers=num_workers,pin_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer.Aggregation_Trainer import Uni_Trainer_sweep\n",
    "from utils.Aggregation_Utils import Survival_Loss,c_index,risk_func\n",
    "run = None \n",
    "epochs = 40\n",
    "storepath = None \n",
    "run_name=\"none\"\n",
    "modality=\"gen\"\n",
    "learningrate=1e-5\n",
    "l1_lambda=1e-7\n",
    "alpha = 0.25\n",
    "\n",
    "\n",
    "run = None\n",
    "criterion = Survival_Loss(alpha) \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learningrate,betas=[0.9,0.999],weight_decay=1e-5,)\n",
    "model_trained = Uni_Trainer_sweep(run,model,optimizer,criterion,training_dataloader,\n",
    "                    val_dataloader,bins,epochs,device,storepath,run_name,\n",
    "                    l1_lambda,modality=modality,testloader=None\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bootstrp(out_all,l_all,c_all,l_con_all):\n",
    "    n_bootstrap = 10\n",
    "    c_idxs = []\n",
    "    for n in range(n_bootstrap):\n",
    "        idx = torch.randint(0,out_all.size(0),size=(out_all.size(0),))\n",
    "        c_idxs.append(c_index(risk_func(out_all[idx]),c_all[idx],l_all[idx]))\n",
    "    #print(c_idxs)\n",
    "    c_idxs = [idx for idx in c_idxs if idx==idx]\n",
    "    return c_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval(model,modelname,dataloader):\n",
    "    #init counter\n",
    "    out_all =torch.empty(size=(0,bins),device='cpu')        \n",
    "    l_all = torch.empty(size=(0,),device='cpu').to(torch.int16)\n",
    "    l_con_all = torch.empty(size=(0,),device='cpu').to(torch.int16)\n",
    "    c_all = torch.empty(size=(0,),device='cpu').to(torch.int16)\n",
    "    val_r = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for  idx,(x,c,l,l_con) in enumerate(dataloader):\n",
    "            x = x.to(device)\n",
    "            out = model(x)\n",
    "            out = out.cpu()\n",
    "            #loss = criterion(out,l)  #CE loss\n",
    "            loss = criterion(out,c,l)  # TODO add loss regularization \n",
    "            val_r += loss.item()\n",
    "            \n",
    "            out_all = torch.cat((out_all,out),dim=0)\n",
    "            l_all = torch.cat((l_all,l),dim=0)\n",
    "            c_all = torch.cat((c_all,c),dim=0)\n",
    "            l_con_all = torch.cat((l_con_all,l_con),dim=0)\n",
    "            \n",
    "\n",
    "    c_idx_full = c_index(out_all,c_all,l_con_all)\n",
    "    \n",
    "    c_idx_bootstrp = bootstrp(out_all,l_all,c_all,l_con_all)\n",
    "    return c_idx_bootstrp,c_idx_full,c_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fig,axis = plt.subplots(1,4,figsize=(12,6))\n",
    "model1 =  SNN_Survival(d_gen,d_gen_out,bins,device,activation=\"SELU\").to(device)\n",
    "model2 =  SNN_Survival(d_gen,d_gen_out,bins,device,activation=\"SELU\").to(device)\n",
    "model3 =  SNN_Survival(d_gen,d_gen_out,bins,device,activation=\"SELU\").to(device)\n",
    "plt.clf\n",
    "allmodels = [[model1,\"random weights\"],\n",
    "             [model2,\"random weights\"],\n",
    "             [model3,\"random weights\"],\n",
    "             [model_trained,\"trained\"],\n",
    "             ]\n",
    "for idx,mod in enumerate(allmodels):\n",
    "    c_idxs1,c_idx_full1,c_train = eval(mod[0],mod[1],training_dataloader)\n",
    "    c_idxs2,c_idx_full2,c_test = eval(mod[0],mod[1],test_dataloader)\n",
    "    c_idxs3,c_idx_full3,c_val = eval(mod[0],mod[1],val_dataloader)\n",
    "    axis[idx].set_title(mod[1])    \n",
    "    axis[idx].hist(c_idxs3,bins = 50,label = f\"val,mean:{round(np.mean(c_idxs3),3)}\", color=\"blue\")\n",
    "    axis[idx].hist(c_idxs2,bins = 50,label = f\"test,mean:{round(np.mean(c_idxs2),3)}\", color=\"green\")\n",
    "    axis[idx].hist(c_idxs1,bins = 50,label = f\"train,mean:{round(np.mean(c_idxs1),3)}\", color=\"red\")\n",
    "    axis[idx].legend()\n",
    "plt.show()\n",
    "#Bootstrap c-index distribution for 3 random and 1 trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = []\n",
    "test_mean = []\n",
    "val_mean = []\n",
    "train_evaluated = []\n",
    "test_evaluated = []\n",
    "val_evaluated = []\n",
    "\n",
    "for idx in range(100):\n",
    "    random_model =  SNN_Survival(d_gen,d_gen_out,bins,device,activation=\"SELU\").to(device)\n",
    "    c_idxs1,c_idx_full1,c_train = eval(random_model,idx,training_dataloader)\n",
    "    c_idxs2,c_idx_full2,c_test = eval(random_model,idx,test_dataloader)\n",
    "    c_idxs3,c_idx_full3,c_val = eval(random_model,idx,val_dataloader)\n",
    "    train_mean.append(np.mean(c_idxs1))\n",
    "    test_mean.append(np.mean(c_idxs2))\n",
    "    val_mean.append(np.mean(c_idxs3))\n",
    "    train_evaluated.append(c_idx_full1)\n",
    "    test_evaluated.append(c_idx_full2)\n",
    "    val_evaluated.append(c_idx_full3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"c-index distribution with random models\")\n",
    "\n",
    "plt.hist(val_evaluated,bins=20,color = \"blue\",label=\"val\")\n",
    "plt.hist(test_evaluated,bins=20,color = \"green\",label=\"test\")\n",
    "plt.hist(train_evaluated,bins=20,color = \"red\",label=\"train\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "train_mean = []\n",
    "test_mean = []\n",
    "val_mean = []\n",
    "train_evaluated = []\n",
    "test_evaluated = []\n",
    "val_evaluated = []\n",
    "\n",
    "for idx in range(100):\n",
    "    random_model =  SNN_Survival(d_gen,d_gen_out,bins,device,activation=\"SELU\").to(device)\n",
    "    optimizer = torch.optim.Adam(random_model.parameters(),lr=learningrate,betas=[0.9,0.999],weight_decay=1e-5,)\n",
    "    mod = Uni_Trainer_sweep(run,random_model,optimizer,criterion,training_dataloader,\n",
    "                    val_dataloader,bins,epochs,device,storepath,run_name,\n",
    "                    l1_lambda,modality=modality,batchsize=batchsize,testloader=None\n",
    "                    )\n",
    "    c_idxs1,c_idx_full1,c_train = eval(mod,idx,training_dataloader)\n",
    "    c_idxs2,c_idx_full2,c_test = eval(mod,idx,test_dataloader)\n",
    "    c_idxs3,c_idx_full3,c_val = eval(mod,idx,val_dataloader)\n",
    "    train_mean.append(np.mean(c_idxs1))\n",
    "    test_mean.append(np.mean(c_idxs2))\n",
    "    val_mean.append(np.mean(c_idxs3))\n",
    "    train_evaluated.append(c_idx_full1)\n",
    "    test_evaluated.append(c_idx_full2)\n",
    "    val_evaluated.append(c_idx_full3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"c-index distribution with trained\")\n",
    "\n",
    "plt.hist(val_evaluated,bins=20,color = \"blue\",label=\"val\")\n",
    "plt.hist(test_evaluated,bins=20,color = \"green\",label=\"test\")\n",
    "plt.hist(train_evaluated,bins=20,color = \"red\",label=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "train_mean = []\n",
    "test_mean = []\n",
    "val_mean = []\n",
    "train_evaluated = []\n",
    "test_evaluated = []\n",
    "val_evaluated = []\n",
    "\n",
    "random_init =  SNN_Survival(d_gen,d_gen_out,bins,device,activation=\"SELU\").to(device)\n",
    "\n",
    "for idx in range(100):\n",
    "    random_model =  SNN_Survival(d_gen,d_gen_out,bins,device,activation=\"SELU\")\n",
    "    random_model.load_state_dict(random_init.state_dict())\n",
    "    random_model.to(device)\n",
    "    optimizer = torch.optim.Adam(random_model.parameters(),lr=learningrate,betas=[0.9,0.999],weight_decay=1e-5,)\n",
    "    mod = Uni_Trainer_sweep(run,random_model,optimizer,criterion,training_dataloader,\n",
    "                    val_dataloader,bins,epochs,device,storepath,run_name,\n",
    "                    l1_lambda,modality=modality,batchsize=batchsize,testloader=None\n",
    "                    )\n",
    "    c_idxs1,c_idx_full1,c_train = eval(mod,idx,training_dataloader)\n",
    "    c_idxs2,c_idx_full2,c_test = eval(mod,idx,test_dataloader)\n",
    "    c_idxs3,c_idx_full3,c_val = eval(mod,idx,val_dataloader)\n",
    "    train_mean.append(np.mean(c_idxs1))\n",
    "    test_mean.append(np.mean(c_idxs2))\n",
    "    val_mean.append(np.mean(c_idxs3))\n",
    "    train_evaluated.append(c_idx_full1)\n",
    "    test_evaluated.append(c_idx_full2)\n",
    "    val_evaluated.append(c_idx_full3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"c-index distribution with trained\")\n",
    "\n",
    "plt.hist(val_evaluated,bins=20,color = \"blue\",label=\"val\")\n",
    "plt.hist(test_evaluated,bins=20,color = \"green\",label=\"test\")\n",
    "plt.hist(train_evaluated,bins=20,color = \"red\",label=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"c-index distribution with trained\")\n",
    "\n",
    "plt.hist(val_mean,bins=20,color = \"blue\",label=\"val\")\n",
    "plt.hist(test_mean,bins=20,color = \"green\",label=\"test\")\n",
    "plt.hist(train_mean,bins=20,color = \"red\",label=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"c-index distribution with trained\")\n",
    "\n",
    "plt.hist(val_evaluated,bins=20,color = \"blue\",label=\"val\")\n",
    "plt.hist(test_evaluated,bins=20,color = \"green\",label=\"test\")\n",
    "plt.hist(train_evaluated,bins=20,color = \"red\",label=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train: from {len(c_train)}, {c_train.sum()} are censored\")\n",
    "print(f\"test: from {len(c_test)}, {c_test.sum()} are censored\")\n",
    "print(f\"val: from {len(c_val)}, {c_val.sum()} are censored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "a = torch.rand((5,512))\n",
    "b = torch.rand((4,512))\n",
    "c = torch.rand((3,512))\n",
    "\n",
    "d = [a,b,c]\n",
    "torch.cat(d,dim=0).size()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Aggregation_Models import SNN_Survival\n",
    "from datasets.Aggregation_DS import Gen_Dataset\n",
    "import os \n",
    "import torch \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "bins = 4\n",
    "\n",
    "device ='cuda' if  torch.cuda.is_available() else 'cpu'\n",
    "storepath = None\n",
    "run_name = None\n",
    "d_gen_out = 32\n",
    "feature_path = \"/nodes/bevog/work4/seibel/data/TCGA-BRCA-DX-features/vit_mae_tiny_I1K_PT_FT_50eps_TCGA_BRCA_features/pt_files\"\n",
    "num_workers = 1\n",
    "csv_path_train = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_trainsplit.csv\"\n",
    "csv_path_test = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_testsplit.csv\"\n",
    "csv_path_val = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_valsplit.csv\"\n",
    "\n",
    "df_train = pd.read_csv(csv_path_train)\n",
    "df_test = pd.read_csv(csv_path_test)\n",
    "df_val = pd.read_csv(csv_path_val)\n",
    "\n",
    "train_ds = Gen_Dataset(df_train,data_path = feature_path,mode=\"train\")\n",
    "val_ds = Gen_Dataset(df_val,data_path = feature_path,mode=\"val\")\n",
    "test_ds = Gen_Dataset(df_test,data_path = feature_path,mode=\"test\")\n",
    "d_gen = train_ds.gen_depth()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer.Aggregation_Trainer import Uni_Trainer_sweep\n",
    "from utils.Aggregation_Utils import Survival_Loss\n",
    "batchsize = 32\n",
    "epochs = 40 \n",
    "l1_lambda = 1e-7\n",
    "modality=\"gen\"\n",
    "alpha = 0.25\n",
    "learningrate = 1e-3\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader( train_ds,batch_size=batchsize,num_workers=num_workers,pin_memory=False)\n",
    "testloader = torch.utils.data.DataLoader(test_ds,batch_size=batchsize,num_workers=num_workers,pin_memory=False)\n",
    "valloader = torch.utils.data.DataLoader(val_ds,batch_size=batchsize,num_workers=num_workers,pin_memory=False)\n",
    "\n",
    "criterion = Survival_Loss(alpha) \n",
    "\n",
    "\n",
    "\n",
    "model = SNN_Survival(d_gen,d_gen_out,bins,device,activation=\"SELU\").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learningrate,betas=[0.9,0.999],weight_decay=1e-5,)\n",
    "\n",
    "#Uni_Trainer_sweep(run=None,model=model,optimizer=optimizer,criterion=criterion,trainloader=trainloader,\n",
    "#                      valloader=valloader,bins=bins,epochs=epochs,device=device,storepath=None,run_name=None,\n",
    "#                      l1_lambda=l1_lambda,modality=modality,testloader=testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputvals = []\n",
    "modelweightslist = []\n",
    "for i in range(60):\n",
    "    model = SNN_Survival(d_gen,d_gen_out,bins,device,activation=\"SELU\").to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=learningrate,betas=[0.9,0.999],weight_decay=1e-5,)\n",
    "    \n",
    "    c_train,c_test,c_val,modelweights = Uni_Trainer_sweep(run=None,model=model,optimizer=optimizer,criterion=criterion,trainloader=trainloader,\n",
    "                      valloader=valloader,bins=bins,epochs=epochs,device=device,storepath=None,run_name=None,\n",
    "                      l1_lambda=l1_lambda,modality=modality,testloader=testloader)\n",
    "\n",
    "    outputvals.append([c_train,c_test,c_val])\n",
    "    modelweightslist.append(modelweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "ctrain = np.array(outputvals).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "nbins = 10\n",
    "\n",
    "plt.clf\n",
    "plt.title(\"c-index for 60 trainings,same hyperparams, random init weights \")\n",
    "plt.hist(ctrain[2],color = \"red\",label = f\"val, mu:{round(np.mean(ctrain[2]),2)}, std:{round(np.std(ctrain[2]),2)}\",bins = nbins,density=True)\n",
    "plt.hist(ctrain[1],color = \"green\",label = f\"test, mu:{round(np.mean(ctrain[1]),2)}, std:{round(np.std(ctrain[1]),2)}\",bins = nbins,density=True)\n",
    "plt.hist(ctrain[0],color = \"blue\",label = f\"train, mu:{round(np.mean(ctrain[0]),2)}, std:{round(np.std(ctrain[0]),2)}\",bins = nbins,density=True)\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"$$%beta$$\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "f = \"/nodes/bevog/work4/seibel/data/aggregation_kfold_dataframes/tcga_brca_trainable4.csv\"\n",
    "data_path = None\n",
    "df = pd.read_csv(f)\n",
    "\n",
    "criterion = Survival_Loss(alpha) \n",
    "\n",
    "\n",
    "outputvals = []\n",
    "modelweightslist = []\n",
    "for j in range(5):\n",
    "    outputvals_k = []\n",
    "    modelweightslist_k = []\n",
    "    \n",
    "    df.kfold = df.kfold.apply(lambda x: (x+1)%5)\n",
    "    dataset_train  = Gen_Dataset(df,data_path,train=\"train\",mode=\"kfold\")\n",
    "    dataset_val  = Gen_Dataset(df,data_path,train=\"test\",mode=\"kfold\")\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(dataset_train,batch_size=batchsize,num_workers=num_workers,pin_memory=False)\n",
    "    valloader = torch.utils.data.DataLoader(dataset_val,batch_size=batchsize,num_workers=num_workers,pin_memory=False)\n",
    "\n",
    "    for i in range(1):\n",
    "        model = SNN_Survival(d_gen,d_gen_out,bins,device,activation=\"SELU\").to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=learningrate,betas=[0.9,0.999],weight_decay=1e-5,)\n",
    "        \n",
    "        c_train,c_val,modelweights = Uni_Trainer_sweep(run=None,model=model,optimizer=optimizer,criterion=criterion,trainloader=trainloader,\n",
    "                        valloader=valloader,bins=bins,epochs=epochs,device=device,storepath=None,run_name=None,\n",
    "                        l1_lambda=l1_lambda,modality=modality,testloader=None)\n",
    "\n",
    "        outputvals_k.append([c_train,c_val])\n",
    "        modelweightslist_k.append(modelweights)\n",
    "    outputvals.append(outputvals_k)\n",
    "    modelweightslist.append(modelweightslist_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputvals = np.array(outputvals) # dim : n_folds,n-repeats,(c_train,c_val)\n",
    "print(outputvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(outputvals,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"/nodes/bevog/work4/seibel/data/aggregation_kfold_dataframes/tcga_brca_trainable4.csv\"\n",
    "data_path = None\n",
    "df = pd.read_csv(f)\n",
    "print(df.kfold.unique())\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if i!=j:\n",
    "            list_a = list(df[df.kfold==i].case_id)\n",
    "            list_b = list(df[df.kfold==j].case_id)\n",
    "            print(i,j,len(list_a))\n",
    "            for id in list_a:\n",
    "                if id in list_b:\n",
    "                    print(id)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "cvals = [[[0.8239960459656493, 0.48894585068888174, 0.48001977017175335, 0.49791733418776035], [0.7955022859261089, 0.47196411406600447, 0.5248239219078216, 0.46395386094200575]], [[0.8311854785176368, 0.6738105443634805, 0.4659051891867146, 0.5910844406343764], [0.8149335042461144, 0.7389627089584226, 0.5306841852267264, 0.7021003000428633]], [[0.775030677634868, 0.5723384895359418, 0.514407126300959, 0.6151046405823476], [0.8049811389355996, 0.47179253867151955, 0.4764577557605781, 0.5555050045495905]], [[0.7871647652424627, 0.6055538024613443, 0.4177913652971441, 0.5932470810981382], [0.7740909203887356, 0.6102871568318081, 0.4722740039271245, 0.4234774376775008]], [[0.7780346820809249, 0.527189705271897, 0.48897109826589596, 0.34412619344126194], [0.7803005780346821, 0.5442092154420921, 0.5424739884393064, 0.40846824408468246]]]\n",
    "cvals = np.asarray(cvals) # 5folds, 2 repetitions, (c_train_c_val;c_train_rand,c_val_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "print(torch.tensor(np.asarray([[1*1000,22435],[3432,424]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def dropmissing(df,name,feature_path):\n",
    "        len_df = len(df)\n",
    "        df = df.drop(df[df[\"slide_id\"].apply(lambda x : not os.path.exists(os.path.join(feature_path,x.replace(\".svs\",\".h5\"))))].index)\n",
    "        if len_df !=len(df):\n",
    "            print(f\"Dropped {len_df-len(df)}rows in {name} dataframe\")\n",
    "        return df\n",
    "f1= \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_trainsplit.csv\"\n",
    "f2= \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_testsplit.csv\"\n",
    "f3= \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_valsplit.csv\"\n",
    "\n",
    "data_path = None\n",
    "df1 = pd.read_csv(f1)\n",
    "df2 = pd.read_csv(f2)\n",
    "df3 = pd.read_csv(f3)\n",
    "df1 = df1[df1[\"traintest\"]==0]\n",
    "df2 = df2[df2[\"traintest\"]==1]\n",
    "df3 = df3[df3[\"traintest\"]==2]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(df1.case_id):\n",
    "    if i in list(df3.case_id):\n",
    "        print(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(columns=[\"traintest\"])\n",
    "df3 = df3.drop(columns=[\"traintest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(columns=[\"kfold\"])\n",
    "#df1 = df1.drop(columns=[\"traintest\"])\n",
    "for i in range(len(df3)):\n",
    "    slide_id = df1[\"slide_id\"][i]\n",
    "    if not df[df[\"slide_id\"]==slide_id].equals(df1[df1[\"slide_id\"]==slide_id]):\n",
    "        print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1[\"slide_id\"]==slide_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.kfold.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "a = np.array([0,1,2,3,4])\n",
    "for fold in(a):\n",
    "    print(fold)\n",
    "    print((a+fold)%len(a))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.keys()[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.keys()[:11]].groupby(\"kfold\").mean(\"censoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df= pd.concat([df1,df2,df3]).drop(columns = [\"traintest\"]).sort_values(by=\"slide_id\")\n",
    "df_kfold = df.copy().drop(columns = [\"kfold\"]).sort_values(by=\"slide_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(df_kfold)):\n",
    "    if not (df_kfold.iloc[idx]==new_df.iloc[idx]).all():\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "train_df = df[df[\"kfold\"]>0].copy()\n",
    "test_df = df[df[\"kfold\"]==0].copy()\n",
    "f_new = \"/nodes/bevog/work4/seibel/data/testkfoldtott/\" # +  tcga_brca__4bins_trainsplit.csv\"\n",
    "train_df = train_df.rename(columns  ={\"kfold\":\"traintest\"})\n",
    "test_df = test_df.rename(columns  ={\"kfold\":\"traintest\"})\n",
    "val_df = train_df[:80]\n",
    "train_df = train_df[80:]\n",
    "\n",
    "train_df[\"traintest\"]=0\n",
    "val_df[\"traintest\"] = 2\n",
    "test_df[\"traintest\"]=1\n",
    "\n",
    "\n",
    "train_df.to_csv(os.path.join(f_new,\"tcga_brca__4bins_trainsplit.csv\"),index=False)\n",
    "val_df.to_csv(os.path.join(f_new,\"tcga_brca__4bins_valsplit.csv\"),index=False)\n",
    "test_df.to_csv(os.path.join(f_new,\"tcga_brca__4bins_testsplit.csv\"),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(f_new,\"tcga_brca__4bins_trainsplit.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.censorship.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "f1 = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_trainsplit.csv\"\n",
    "f2 = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_valsplit.csv\"\n",
    "\n",
    "df1 = pd.read_csv(f1)\n",
    "df2 = pd.read_csv(f2)\n",
    "\n",
    "result = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "case_ids = result['case_id'].unique()\n",
    "np.random.seed(1234)  \n",
    "kfolds = 4\n",
    "np.random.shuffle(case_ids)\n",
    "diction = dict([(name,idx) for idx,name in enumerate(case_ids) ])\n",
    "result[\"traintest\"] = result.case_id.map(diction)%kfolds\n",
    "result = result.rename(columns={\"traintest\":\"kfold\"})\n",
    "f_out = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_4fold_on_trainval_split.csv\"\n",
    "result.to_csv(f_out,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_ids = result['case_id'].unique()\n",
    "np.random.seed(1234)  \n",
    "kfolds = 4\n",
    "np.random.shuffle(case_ids)\n",
    "diction = dict([(name,idx) for idx,name in enumerate(case_ids) ])\n",
    "result[\"traintest\"] = result.case_id.map(diction)%kfolds\n",
    "result = result.rename(columns={\"traintest\":\"kfold\"})\n",
    "f_out = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_4fold_on_trainval_split.csv\"\n",
    "result.to_csv(f_out,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "f = \"/nodes/bevog/work4/seibel/data/aggregation_kfold_dataframes/trainvalidation_4foldsplit/tcga_brca_trainable4.csv\"\n",
    "df = pd.read_csv(f)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,1,2,3]:\n",
    "    l1 = df[df.kfold==i].case_id.unique()\n",
    "    for j in [0,1,2,3]:\n",
    "        if i!=j:\n",
    "            l2 = df[df.kfold==j].case_id.unique()\n",
    "            print(i,j)\n",
    "            for id in l1:\n",
    "                if id in l2:\n",
    "                    print(id)\n",
    "        else:\n",
    "            print(i,j)\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUgmentation experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "#!pip install umap-learn\n",
    "import umap.umap_ as umap\n",
    "n = 1000\n",
    "d = 20000\n",
    "eps = 0.1#set to 0.5\n",
    "clusters = 25#set to  5 \n",
    "\n",
    "vecs =[]\n",
    "Y = []\n",
    "for i in range(clusters):\n",
    "    mu = torch.rand((1,d))*0.1\n",
    "    vecs.append(torch.rand((n//clusters,d))+mu)\n",
    "    Y+=[i]*(n//clusters)\n",
    "vecs = torch.cat(vecs,dim=0)\n",
    "Y = np.asarray(Y)   \n",
    "aug = eps*torch.rand((n,d))\n",
    "#vec_lens = torch.norm(vecs,dim=1)\n",
    "#aug_len =  torch.norm(aug,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embed_model_umap = umap.UMAP(n_components = 2,init='random',\n",
    "                         random_state=0)\n",
    "X_embed_model_umap.fit(vecs.numpy())\n",
    "\n",
    "X_emb = X_embed_model_umap.transform(vecs.numpy()).T\n",
    "df = pd.DataFrame(np.asarray([X_emb[0],X_emb[1],Y]).T,columns=[\"umap_x\",\"umap_y\",\"Classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"umap_x\", y=\"umap_y\",hue = \"Classes\",palette='viridis',legend='full',data=df,alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emb = X_embed_model_umap.fit_transform((vecs+aug).numpy()).T\n",
    "df_aug = pd.DataFrame(np.asarray([X_emb[0],X_emb[1],Y]).T,columns=[\"umap_x\",\"umap_y\",\"Classes\"])\n",
    "sns.scatterplot(x=\"umap_x\", y=\"umap_y\",hue = \"Classes\",palette='viridis',legend='full',data=df_aug,alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#f = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_trainsplit.csv\"\n",
    "\n",
    "f = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/DF_TCGA-BRCA-TIILES-NORM.csv\"\n",
    "df = pd.read_csv(f)\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3\n",
    "#random shuffle df before!\n",
    "random_shuffle = ...\n",
    "\n",
    "new_df = []\n",
    "for idx,(slide_id, group) in enumerate(df.groupby('slide_id')):\n",
    "    k = len(group)\n",
    "    rest = k%n\n",
    "    new_group = group.reset_index().drop(index = [i for i in range(k-rest,k)]) #new index for group, drop rest tiles\n",
    "    new_group = np.stack(np.array_split(new_group['tilepath'], n),axis=1) # stack into sets of  n files together \n",
    "    new_group = pd.DataFrame(new_group,columns=[f\"tilepath_{i}\" for i in range(n)]) # create new pd dataframe\n",
    "    new_group['slide_id'] = slide_id\n",
    "    new_df.append(new_group)\n",
    "    \n",
    "new_df = pd.concat(new_df)\n",
    "\n",
    "for i in range(n):\n",
    "    #extract coords from tilepath \n",
    "    new_df[f\"tile_coords_{i}\"] = new_df[f\"tilepath_{i}\"].apply(lambda x :  x.split(\"(\")[1].split(\")\")[0].split(\",\"))\n",
    "    new_df[f\"tile_coords_{i}\"] = new_df[f\"tile_coords_{i}\"].apply(lambda x: [int(x[0]),int(x[1])])\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = df[\"tilepath\"].apply(lambda x :  x.split(\"(\")[1].split(\")\")[0].split(\",\"))\n",
    "vals = vals.apply(lambda x: [int(x[0]),int(x[1])])\n",
    "vals = np.asarray(list(vals)).T\n",
    "\n",
    "print(vals.max())\n",
    "print(vals.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df_xy = pd.DataFrame({\"x\":vals[0],\"y\":vals[1]})\n",
    "df_xy[\"slide_id\"] = df[\"slide_id\"]\n",
    "sns.scatterplot(data=df_xy[df_xy[\"slide_id\"]==df[\"slide_id\"].unique()[13]],x=\"x\",y=\"y\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def get_coords(tilepath):\n",
    "    x,y = tilepath.split(\"(\")[1].split(\")\")[0].split(\",\")\n",
    "    return [int(x),int(y)]\n",
    "feature_path = \"/globalwork/seibel/TCGA-BRCA-TILES-NORM\"\n",
    "f = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/DF_TCGA-BRCA-TIILES-NORM.csv\"\n",
    "df = pd.read_csv(f)\n",
    "print(df.keys())    \n",
    "df[\"coords\"] = df[\"tilepath\"].apply(get_coords) # add coordinates from tilepath as additional column \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "new_df = []\n",
    "do_knn = False\n",
    "for idx,(slide_id, group) in enumerate(df.groupby('slide_id')):\n",
    "    group = group.reset_index(drop=True)\n",
    "    coords = np.array(list(group[\"coords\"]))\n",
    "    if do_knn:\n",
    "        nn = NearestNeighbors(n_neighbors=k, algorithm='ball_tree')\n",
    "        nn.fit(coords)\n",
    "        distances, indices = nn.kneighbors(coords)\n",
    "        indices = np.array(indices)\n",
    "        for i in range(1,k):\n",
    "            group[f\"{i}_NN_tilepath\"]=  list(group.iloc[indices[:,i]][\"tilepath\"])\n",
    "    else:\n",
    "        for i in range(1,k):\n",
    "            group[f\"{i}_rand_tilepath\"]=  list(group[\"tilepath\"].sample(frac=1,random_state=(1+i)))\n",
    "    new_df.append(group.copy())\n",
    "    \n",
    "new_df = pd.concat(new_df).reset_index(drop=True)\n",
    "new_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(tilepath):\n",
    "    x,y = tilepath.split(\"(\")[1].split(\")\")[0].split(\",\")\n",
    "    return [int(x),int(y)]\n",
    "\n",
    "def make_newDF(f,k,do_knn=True):\n",
    "    #create k nearest neighbours \n",
    "    k = k+1\n",
    "    df = pd.read_csv(f)\n",
    "    cols = [\"slide_id\",\"tilepath\"]\n",
    "    missing_idx = [name not in df.keys() for name in cols]\n",
    "    assert not any(missing_idx) ,f\"Dataframe is missing keys:{np.array(cols)[missing_idx]}\"\n",
    "    assert len(df) >0,\"given dataset is empty\"\n",
    "    \n",
    "    df[\"coords\"] = df[\"tilepath\"].apply(get_coords)\n",
    "    \n",
    "    new_df = []\n",
    "    for idx,(slide_id, group) in enumerate(df.groupby('slide_id')):\n",
    "        group = group.reset_index(drop=True)\n",
    "        coords = np.array(list(group[\"coords\"]))\n",
    "        if do_knn:\n",
    "            nn = NearestNeighbors(n_neighbors=k, algorithm='ball_tree')\n",
    "            nn.fit(coords)\n",
    "            distances, indices = nn.kneighbors(coords)\n",
    "            indices = np.array(indices)\n",
    "            for i in range(1,k):\n",
    "                group[f\"{i}_NN_tilepath\"]=  list(group.iloc[indices[:,i]][\"tilepath\"])\n",
    "        else:\n",
    "            for i in range(1,k):\n",
    "                group[f\"{i}_rand_tilepath\"]=  list(group[\"tilepath\"].sample(frac=1,random_state=(1+i)))\n",
    "        new_df.append(group.copy())\n",
    "    new_df = pd.concat(new_df).reset_index(drop=True)\n",
    "    return new_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df = make_newDF(f,k=10)\n",
    "new_df = make_newDF(f,k=10,do_knn=False)\n",
    "f_save = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/DF_TCGA-BRCA-Tiles_Multitileds_rand.csv\"\n",
    "new_df.to_csv(f_save,index=False)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tilepath</th>\n",
       "      <th>slide_id</th>\n",
       "      <th>coords</th>\n",
       "      <th>1_rand_tilepath</th>\n",
       "      <th>2_rand_tilepath</th>\n",
       "      <th>3_rand_tilepath</th>\n",
       "      <th>4_rand_tilepath</th>\n",
       "      <th>5_rand_tilepath</th>\n",
       "      <th>6_rand_tilepath</th>\n",
       "      <th>7_rand_tilepath</th>\n",
       "      <th>8_rand_tilepath</th>\n",
       "      <th>9_rand_tilepath</th>\n",
       "      <th>10_rand_tilepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>TCGA-3C-AALI-01Z-00-DX1.F6E9A5DF-D8FB-45CF-B4B...</td>\n",
       "      <td>[44032, 27648]</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>TCGA-3C-AALI-01Z-00-DX1.F6E9A5DF-D8FB-45CF-B4B...</td>\n",
       "      <td>[65536, 7168]</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>TCGA-3C-AALI-01Z-00-DX1.F6E9A5DF-D8FB-45CF-B4B...</td>\n",
       "      <td>[56320, 67584]</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>TCGA-3C-AALI-01Z-00-DX1.F6E9A5DF-D8FB-45CF-B4B...</td>\n",
       "      <td>[39936, 41984]</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>TCGA-3C-AALI-01Z-00-DX1.F6E9A5DF-D8FB-45CF-B4B...</td>\n",
       "      <td>[45056, 29696]</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943700</th>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>TCGA-Z7-A8R6-01Z-00-DX1.CE4ED818-D762-4324-9DE...</td>\n",
       "      <td>[29378, 53692]</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943701</th>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>TCGA-Z7-A8R6-01Z-00-DX1.CE4ED818-D762-4324-9DE...</td>\n",
       "      <td>[64835, 53692]</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943702</th>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>TCGA-Z7-A8R6-01Z-00-DX1.CE4ED818-D762-4324-9DE...</td>\n",
       "      <td>[82057, 31404]</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943703</th>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>TCGA-Z7-A8R6-01Z-00-DX1.CE4ED818-D762-4324-9DE...</td>\n",
       "      <td>[58757, 17222]</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943704</th>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>TCGA-Z7-A8R6-01Z-00-DX1.CE4ED818-D762-4324-9DE...</td>\n",
       "      <td>[37483, 15195]</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "      <td>/globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2943705 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tilepath  \\\n",
       "0        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "1        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "2        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "3        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "4        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "...                                                    ...   \n",
       "2943700  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943701  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943702  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943703  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943704  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "\n",
       "                                                  slide_id          coords  \\\n",
       "0        TCGA-3C-AALI-01Z-00-DX1.F6E9A5DF-D8FB-45CF-B4B...  [44032, 27648]   \n",
       "1        TCGA-3C-AALI-01Z-00-DX1.F6E9A5DF-D8FB-45CF-B4B...   [65536, 7168]   \n",
       "2        TCGA-3C-AALI-01Z-00-DX1.F6E9A5DF-D8FB-45CF-B4B...  [56320, 67584]   \n",
       "3        TCGA-3C-AALI-01Z-00-DX1.F6E9A5DF-D8FB-45CF-B4B...  [39936, 41984]   \n",
       "4        TCGA-3C-AALI-01Z-00-DX1.F6E9A5DF-D8FB-45CF-B4B...  [45056, 29696]   \n",
       "...                                                    ...             ...   \n",
       "2943700  TCGA-Z7-A8R6-01Z-00-DX1.CE4ED818-D762-4324-9DE...  [29378, 53692]   \n",
       "2943701  TCGA-Z7-A8R6-01Z-00-DX1.CE4ED818-D762-4324-9DE...  [64835, 53692]   \n",
       "2943702  TCGA-Z7-A8R6-01Z-00-DX1.CE4ED818-D762-4324-9DE...  [82057, 31404]   \n",
       "2943703  TCGA-Z7-A8R6-01Z-00-DX1.CE4ED818-D762-4324-9DE...  [58757, 17222]   \n",
       "2943704  TCGA-Z7-A8R6-01Z-00-DX1.CE4ED818-D762-4324-9DE...  [37483, 15195]   \n",
       "\n",
       "                                           1_rand_tilepath  \\\n",
       "0        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "1        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "2        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "3        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "4        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "...                                                    ...   \n",
       "2943700  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943701  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943702  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943703  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943704  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "\n",
       "                                           2_rand_tilepath  \\\n",
       "0        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "1        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "2        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "3        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "4        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "...                                                    ...   \n",
       "2943700  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943701  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943702  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943703  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943704  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "\n",
       "                                           3_rand_tilepath  \\\n",
       "0        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "1        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "2        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "3        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "4        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "...                                                    ...   \n",
       "2943700  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943701  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943702  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943703  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943704  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "\n",
       "                                           4_rand_tilepath  \\\n",
       "0        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "1        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "2        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "3        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "4        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "...                                                    ...   \n",
       "2943700  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943701  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943702  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943703  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943704  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "\n",
       "                                           5_rand_tilepath  \\\n",
       "0        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "1        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "2        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "3        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "4        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "...                                                    ...   \n",
       "2943700  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943701  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943702  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943703  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943704  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "\n",
       "                                           6_rand_tilepath  \\\n",
       "0        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "1        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "2        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "3        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "4        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "...                                                    ...   \n",
       "2943700  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943701  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943702  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943703  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943704  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "\n",
       "                                           7_rand_tilepath  \\\n",
       "0        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "1        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "2        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "3        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "4        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "...                                                    ...   \n",
       "2943700  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943701  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943702  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943703  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943704  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "\n",
       "                                           8_rand_tilepath  \\\n",
       "0        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "1        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "2        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "3        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "4        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "...                                                    ...   \n",
       "2943700  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943701  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943702  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943703  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943704  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "\n",
       "                                           9_rand_tilepath  \\\n",
       "0        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "1        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "2        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "3        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "4        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...   \n",
       "...                                                    ...   \n",
       "2943700  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943701  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943702  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943703  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "2943704  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...   \n",
       "\n",
       "                                          10_rand_tilepath  \n",
       "0        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...  \n",
       "1        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...  \n",
       "2        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...  \n",
       "3        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...  \n",
       "4        /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-3...  \n",
       "...                                                    ...  \n",
       "2943700  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...  \n",
       "2943701  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...  \n",
       "2943702  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...  \n",
       "2943703  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...  \n",
       "2943704  /globalwork/seibel/TCGA-BRCA-TILES-NORM/TCGA-Z...  \n",
       "\n",
       "[2943705 rows x 13 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "datafframe = pd.read_csv(\"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/DF_TCGA-BRCA-Tiles_Multitileds_rand.csv\")\n",
    "datafframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "for key in list(datafframe.keys()[3:]):\n",
    "    print(all(datafframe[key].apply(lambda x : os.path.exists(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Encoder_Models import ViTMAEtiny_gen,SupViTSurv_nogen\n",
    "import torch \n",
    "model = ViTMAEtiny_gen(lr=0.001,aggregation_func=\"Mean_Aggregation\",genomics=True,nbins=4,alpha=0.25,mask_ratio=0.75,encode_gen=True)\n",
    "model2 = SupViTSurv_nogen(lr=0.001,nbins=4,alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 10 \n",
    "hist_tile = torch.rand((B,3,224,224))\n",
    "gen=torch.rand((B,20971))\n",
    "censorship = torch.randint(0,1,(B,))\n",
    "label = torch.randint(0,4,(B,))\n",
    "label_cont = torch.rand((B,))\n",
    "\n",
    "batch = (hist_tile,gen, censorship, label,label_cont)\n",
    "#model.training_step(batch,0)\n",
    "#model.predict_step( (hist_tile,gen),0,mask_ratio=0)\n",
    "model.validation_step(batch,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.training_step(batch,0)\n",
    "model2.predict_step( (hist_tile,gen),0,mask_ratio=0)\n",
    "model2.validation_step(batch,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging multitile SupVit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seibel/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#!pip install --extra-index-url=https://pypi.nvidia.com cudf-cu12\n",
    "import torch \n",
    "from models.Encoder_Models import MultiSupViTSurv\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import pytorch_lightning as pl \n",
    "from datasets.Tile_DS import TileModule\n",
    "\n",
    "#import pandas as pd \n",
    "\n",
    "class MultiTileDummy_train(Dataset):\n",
    "    def __init__(self,n_neighbours,length =1000):\n",
    "        self.length=length\n",
    "        self.n_neighbours=n_neighbours\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    def __getitem__(self,idx):\n",
    "        size = 224\n",
    "        hist_tile = torch.rand(3,size,size)\n",
    "        nn_tiles = [torch.rand(3,size,size) for i in range(self.n_neighbours)]\n",
    "        gen = torch.rand(20971,)\n",
    "        censorship = torch.randint(0,2,size=(1,))\n",
    "        label = torch.randint(0,4,size=())\n",
    "        label_cont = torch.randint(0,80,size=())\n",
    "        batch = ([hist_tile]+nn_tiles,gen, censorship, label,label_cont)\n",
    "        return batch\n",
    "\n",
    "class MultiTileDummy_eval(Dataset):\n",
    "    def __init__(self,length =100):\n",
    "        self.length=length\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    def __getitem__(self,idx):\n",
    "        size = 224\n",
    "        hist_tile = torch.rand(1,3,size,size)\n",
    "        gen = torch.rand(1,20971,)\n",
    "        censorship = torch.randint(0,2,size=(1,))\n",
    "        label = torch.randint(0,4,size=(1,))\n",
    "        label_cont = torch.randint(0,80,size=())\n",
    "        batch = (hist_tile,gen, censorship, label,label_cont)\n",
    "        return batch\n",
    "    \n",
    "class TileModule_dummy(pl.LightningDataModule):\n",
    "    def __init__(self,batch_size = 16,n_neighbours=3):\n",
    "        super().__init__()\n",
    "        self.n_neighbours = n_neighbours\n",
    "        \n",
    "        self.batch_size = batch_size \n",
    "    def setup(self, stage):\n",
    "        self.dataset_train = MultiTileDummy_train(length = 6000,n_neighbours=self.n_neighbours)\n",
    "        self.dataset_eval = MultiTileDummy_eval(length = 2000)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset_train, batch_size=self.batch_size, shuffle=True,num_workers=0,pin_memory=False)\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        return self.dataset_eval\n",
    "            \n",
    "    def test_dataloader(self):\n",
    "        return self.dataset_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "multitile = True\n",
    "n_neighbours = 3\n",
    "df_path_train = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_trainsplit.csv\"\n",
    "df_path_test = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_testsplit.csv\"\n",
    "df_path_val = \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_valsplit.csv\"\n",
    "tile_df_path_multi =\"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/DF_TCGA-BRCA-Tiles_Multitileds.csv\"\n",
    "tile_df_path= \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/DF_TCGA-BRCA-TIILES-NORM.csv\"\n",
    "batch_size = 64\n",
    "num_workers = 6\n",
    "pin_memory = True\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "#tilemodule = TileModule(df_path_train=df_path_train,df_path_test=df_path_test,tile_df_path=tile_df_path,batch_size=batch_size,num_workers=num_workers,pin_memory=pin_memory,df_path_val=df_path_val,multitile=multitile,n_neighbours=n_neighbours,tile_df_path_multi=tile_df_path_multi )\n",
    "tilemodule =TileModule_dummy(batch_size,n_neighbours=n_neighbours,)\n",
    "model = MultiSupViTSurv(lr = 0.0001,nbins=4,n_neighbours=n_neighbours,alpha=0.25,aggregation_func=\"Mean_Aggregation\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seibel/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/lightning_fabric/connector.py:554: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "  rank_zero_warn(\n",
      "/home/seibel/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:168: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/seibel/.pyenv/versions/3.10.12/envs/env2/lib/p ...\n",
      "  rank_zero_warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.profilers import PyTorchProfiler\n",
    "from pytorch_lightning.callbacks import StochasticWeightAveraging,ModelCheckpoint\n",
    "default_root_dir = \"./\"\n",
    "profiler = PyTorchProfiler(profile_memory=True)\n",
    "trainer = pl.Trainer(profiler=None,precision=16, accelerator=\"gpu\",devices=1,max_steps=120,max_epochs=2,log_every_n_steps=1,\n",
    "                     callbacks=[StochasticWeightAveraging(0.002,annealing_epochs=10,),\n",
    "                                ModelCheckpoint(dirpath=default_root_dir,every_n_epochs=25  ,save_top_k=-1)], logger=False,\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seibel/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:168: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/seibel/.pyenv/versions/3.10.12/envs/env2/lib/p ...\n",
      "  rank_zero_warn(\n",
      "/home/seibel/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /nodes/bevog/work4/seibel/multimodal_survival_prediction exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name                | Type                 | Params\n",
      "-------------------------------------------------------------\n",
      "0 | model               | MaskedAutoencoderViT | 5.7 M \n",
      "1 | classification_head | Classifier_Head      | 41.7 K\n",
      "2 | criterion           | Survival_Loss        | 0     \n",
      "3 | y_encoder           | SNN                  | 5.5 M \n",
      "4 | lin_encs            | ModuleList           | 590 K \n",
      "-------------------------------------------------------------\n",
      "11.7 M    Trainable params\n",
      "56.7 K    Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.868    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seibel/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/94 [00:00<?, ?it/s] "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/nodes/bevog/work4/seibel/multimodal_survival_prediction/Playground.ipynb Cell 156\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvision-bevog/nodes/bevog/work4/seibel/multimodal_survival_prediction/Playground.ipynb#Y311sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, tilemodule,)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n\u001b[0;32m--> 532\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    533\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    534\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m    562\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    566\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    567\u001b[0m     ckpt_path,\n\u001b[1;32m    568\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    570\u001b[0m )\n\u001b[0;32m--> 571\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 980\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    982\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1022\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1023\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1024\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected state \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:202\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 202\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance()\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:355\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(combined_loader)\n\u001b[1;32m    354\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:133\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(data_fetcher)\n\u001b[1;32m    134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    135\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:219\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    217\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    218\u001b[0m         \u001b[39m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mautomatic_optimization\u001b[39m.\u001b[39;49mrun(trainer\u001b[39m.\u001b[39;49moptimizers[\u001b[39m0\u001b[39;49m], kwargs)\n\u001b[1;32m    220\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_optimization\u001b[39m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:188\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         closure()\n\u001b[1;32m    183\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 188\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_step(kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mbatch_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m), closure)\n\u001b[1;32m    190\u001b[0m result \u001b[39m=\u001b[39m closure\u001b[39m.\u001b[39mconsume_result()\n\u001b[1;32m    191\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:266\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_ready()\n\u001b[1;32m    265\u001b[0m \u001b[39m# model hook\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m call\u001b[39m.\u001b[39;49m_call_lightning_module_hook(\n\u001b[1;32m    267\u001b[0m     trainer,\n\u001b[1;32m    268\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39moptimizer_step\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    269\u001b[0m     trainer\u001b[39m.\u001b[39;49mcurrent_epoch,\n\u001b[1;32m    270\u001b[0m     batch_idx,\n\u001b[1;32m    271\u001b[0m     optimizer,\n\u001b[1;32m    272\u001b[0m     train_step_and_backward_closure,\n\u001b[1;32m    273\u001b[0m )\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    276\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:145\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[1;32m    144\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 145\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    147\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    148\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1270\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\n\u001b[1;32m   1233\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1234\u001b[0m     epoch: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1239\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer`\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[39m    calls the optimizer.\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[39m                    pg[\"lr\"] = lr_scale * self.learning_rate\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1270\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49moptimizer_closure)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:161\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    160\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy\u001b[39m.\u001b[39;49moptimizer_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer, closure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_after_step()\n\u001b[1;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:231\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pl\u001b[39m.\u001b[39mLightningModule)\n\u001b[0;32m--> 231\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49moptimizer_step(optimizer, model\u001b[39m=\u001b[39;49mmodel, closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/amp.py:76\u001b[0m, in \u001b[0;36mMixedPrecisionPlugin.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(optimizer, LBFGS):\n\u001b[1;32m     75\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mAMP and the LBFGS optimizer are not compatible.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m closure_result \u001b[39m=\u001b[39m closure()\n\u001b[1;32m     78\u001b[0m \u001b[39m# If backward was skipped in automatic optimization (return None), unscaling is not needed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m skip_unscaling \u001b[39m=\u001b[39m closure_result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m model\u001b[39m.\u001b[39mautomatic_optimization\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:142\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclosure(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39mloss\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:137\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_zero_grad_fn()\n\u001b[1;32m    136\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m step_output\u001b[39m.\u001b[39mclosure_loss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backward_fn(step_output\u001b[39m.\u001b[39;49mclosure_loss)\n\u001b[1;32m    139\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:237\u001b[0m, in \u001b[0;36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001b[0;34m(loss)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward_fn\u001b[39m(loss: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     call\u001b[39m.\u001b[39;49m_call_strategy_hook(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer, \u001b[39m\"\u001b[39;49m\u001b[39mbackward\u001b[39;49m\u001b[39m\"\u001b[39;49m, loss, optimizer)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:293\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    295\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    296\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:205\u001b[0m, in \u001b[0;36mStrategy.backward\u001b[0;34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    203\u001b[0m closure_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mpre_backward(closure_loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module)\n\u001b[0;32m--> 205\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49mbackward(closure_loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module, optimizer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    207\u001b[0m closure_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mpost_backward(closure_loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module)\n\u001b[1;32m    208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_backward(closure_loss)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:69\u001b[0m, in \u001b[0;36mPrecisionPlugin.backward\u001b[0;34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     52\u001b[0m     tensor: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m     57\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     model\u001b[39m.\u001b[39;49mbackward(tensor, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1058\u001b[0m, in \u001b[0;36mLightningModule.backward\u001b[0;34m(self, loss, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1056\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fabric\u001b[39m.\u001b[39mbackward(loss, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1057\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1058\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/env2/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, tilemodule,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "import tracemalloc\n",
    "\n",
    "print((psutil.Process(os.getpid()).memory_info().rss)/(1024 * 1024),' MBs')\n",
    "# starting the monitoring\n",
    "tracemalloc.start()\n",
    " \n",
    "# function call\n",
    "trainer.fit(model, tilemodule,)\n",
    " \n",
    "# displaying the memory\n",
    "print(f\"end:\",tracemalloc.get_traced_memory())\n",
    " \n",
    "# stopping the library\n",
    "\n",
    "print((psutil.Process(os.getpid()).memory_info().rss)/(1024 * 1024),' MBs')\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder import train \n",
    "num_gpus=1\n",
    "\n",
    "\n",
    "config ={\"mode\" : \"train\",\n",
    "    \"wandb_settings\" :{\n",
    "        \"monitoring\" : True,\n",
    "        \"entity\" : \"tobias-seibel\",\n",
    "        \"project\" : \"Feature_Encoder\",\n",
    "        \"name\" : \"maetiny_ft100eps_brca_histo_gen_multitile6\",\n",
    "        },\n",
    "    \"train_settings\": {\n",
    "        \"ffcv\" : False,\n",
    "        \"model_name\" : \"MultiSupViTSurv\",\n",
    "        \"save_dir\" : \"/home/seibel/maetiny_ft100eps_brca_histo_gen_multitile\",\n",
    "        \"max_epochs\" : 100,\n",
    "        \"stochastic_weightaveraging\" : True,\n",
    "        \n",
    "        \"annealing_epochs\" : 110,\n",
    "        \"checkpoint_path\" : None,\n",
    "        \"do_test\" : True,\n",
    "        \"default_root_dir\" : \"/home/seibel/maetiny_ft100eps_brca_histo_gen_multitile\",\n",
    "        \"max_steps\" : 20,\n",
    "        \"monitor_weights_gradients\" : True,\n",
    "        \"profiler\" :None, #simple\n",
    "        \"log_every_n_steps\" : 100,\n",
    "        \"tune\" : False,\n",
    "        \"model_params\" :{\n",
    "                \"lr\" : 0.0001,\n",
    "                \"nbins\" : 4,\n",
    "                \"n_neighbours\" : 3,\n",
    "                \"alpha\" : 0.25,\n",
    "                \"encode_gen\" : True,\n",
    "                \"aggregation_func\" : \"Mean_Aggregation\",\n",
    "                \"ckpt_path\" : \"/nodes/bevog/work4/seibel/data/mae_tiny_400e.pth.tar\",\n",
    "                \"p_dropout_head\" : 0.7},\n",
    "        \"datamodule\" :  \"TileModule\",\n",
    "        \"dataset_params\" : {\n",
    "                \"multitile\" : True,\n",
    "                \"n_neighbours\" : 3,\n",
    "                \"df_path_train\" : \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_trainsplit.csv\",\n",
    "                \"df_path_test\" : \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_testsplit.csv\",\n",
    "                \"df_path_val\" : \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/tcga_brca__4bins_valsplit.csv\",\n",
    "                \"tile_df_path_multi\" : \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/DF_TCGA-BRCA-Tiles_Multitileds.csv\",\n",
    "                \"tile_df_path\" : \"/nodes/bevog/work4/seibel/data/tile_encoder_dataframes/DF_TCGA-BRCA-TIILES-NORM.csv\",\n",
    "                \"batch_size\" : 256,\n",
    "                \"num_workers\" : 4,\n",
    "                \"pin_memory\" : True,\n",
    "            }\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(num_gpus, config[\"train_settings\"],False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "loss1 = [torch.rand(size=()) for i in range(3)]\n",
    "loss2 = torch.rand(size=())\n",
    "torch.stack(loss1+[loss2]).sum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = [1,2,3,4]\n",
    "print(a)\n",
    "a.append(7) if False else print(\"No SGA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,2,3],[1,2,3],[1,2,3],[1,2,3]] \n",
    "b1,b2,b3 = zip(*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

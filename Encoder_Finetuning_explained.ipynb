{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning of Feature encoder\n",
    "\n",
    "A very common way of applying deep learning techniques in digital pathology is Multiple Instance Learning (MIL) \n",
    "The giga pixel image is cropped into a set of equally sized non overlapping tiles. The tiles are encoded with a pretrained feature extractor and then aggregated within in a second step by a trainable model to solve a specific task. \n",
    "Tipically used feature encoders were pretrained either on Imagenet21k or even on larger histological datasets. The architectures of such models can reach from smaller ones like the Resnet18  up to Swim transformer based transformer architectures. \n",
    "Since pre training larger models from scratch requires huge amounts of ressources, the focus of this model is fine tuning a pretrained model. \n",
    "\n",
    "**The following experiments attempt to explore whether existing feature encoders can be fine-tuned for better survival analysis.**\n",
    "\n",
    "\n",
    "The aim is to carry out the following experiments:\n",
    "\n",
    "1. Resnet18: train from scratch/fine tune on Survival Analysis\n",
    "2. ViT Tiny: train from scratch/fine tune on Survival Analysis (+Multimodality)\n",
    "3. Vit Tiny MAE: fine tune on Survival Analysis \n",
    "4. Vit Tiny MAE: fine tune on Survival Analysis in a supMAE fashion\n",
    "\n",
    "To aquire those experiments, the following subtasks are needed: \n",
    "1. Create a custom dataset(from zip) that statifies on a patient level into a train/test split.\n",
    "2. Create models,find checkpoints,load parameters such that DDP is applicable\n",
    "3. Create a training function which allows partially freezing weights, finetune, train from checkpoint.\n",
    "4. Create an encoding pipeline. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader\n",
    "\n",
    "The Data consists of ~1000 patients. Each patient has exactly one genetic feature vector and can have multiple sets(can have multiple slides) of tile-sets.\n",
    "\n",
    "Idea: \n",
    "\n",
    "The dataloader receives a dataframe which contains meta data and genetic data (stratified by train/test split on a patient level)\n",
    "and further a path to the tiles. From this path, an os.walk is done to create a second dataframe which contains the file path and the slide_id.\n",
    "the dataframe will be adapted to contain the tile_path, meta data and the index of the respecitve row within the genomic tensor\n",
    "\n",
    "1. Import Dataframe, create Gen tensor, metadataframe\n",
    "2. os.walk on tilepath to create tile dataframe,\n",
    "3.  add mapping for slide_id idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.)\n",
    "from utils.Aggregation_Utils import *\n",
    "df_train,df_test,df_val = prepare_csv(df_path=\"/work4/seibel/PORPOISE/datasets_csv/tcga_brca_all_clean.csv.zip\",split=\"traintestval\",n_bins=4,save = False,frac_train=0.7,frac_val=0.1)\n",
    "df_train = df_train[df_train[\"traintest\"]==0] # if train \n",
    "\n",
    "\n",
    "\n",
    "genomics_tensor = torch.Tensor(df_train[df_train.keys()[11:]].to_numpy()).to(torch.float32)\n",
    "df_meta = df_train[[\"slide_id\",\"survival_months_discretized\",\"censorship\",\"survival_months\"]]\n",
    "diction = dict([(name,idx) for idx,name in enumerate(df_meta[\"slide_id\"]) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.)\n",
    "import os\n",
    "import pandas as pd\n",
    "tile_path = \"/work4/seibel/data/TCGA-BRCA-TILES/\"\n",
    "ext = \"jpg\"\n",
    "file_list = []\n",
    "root_list = []\n",
    "for root, dirs, files in os.walk(tile_path, topdown=False):\n",
    "    for name in files:\n",
    "        file_list.append(os.path.join(root, name))\n",
    "        root_list.append(root.split(\"/\")[-1]+\".svs\")\n",
    "\n",
    "df_tiles = pd.DataFrame({\"tilepath\":file_list,\"slide_id\":root_list},)\n",
    "df_tiles = df_tiles[df_tiles[\"tilepath\"].str.endswith(ext)] # Avoid having other files than .<ext> files in Dataframe\n",
    "\n",
    "\n",
    "print(df_tiles.tilepath.iloc[0])\n",
    "print(df_tiles.slide_id.iloc[0])\n",
    "df_tiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.)\n",
    "df_tiles.insert(2,\"slideid_idx\",df_tiles[\"slide_id\"].map(diction))\n",
    "df_tiles = df_tiles.dropna()\n",
    "df_tiles.slideid_idx = df_tiles.slideid_idx.astype(int)\n",
    "df_tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.8392, 0.7569, 0.8000,  ..., 0.9373, 0.9373, 0.9412],\n",
       "          [0.7843, 0.7412, 0.7765,  ..., 0.9373, 0.9373, 0.9412],\n",
       "          [0.7373, 0.7412, 0.7608,  ..., 0.9373, 0.9373, 0.9412],\n",
       "          ...,\n",
       "          [0.9255, 0.9294, 0.9176,  ..., 0.9451, 0.9529, 0.9412],\n",
       "          [0.9373, 0.9294, 0.9059,  ..., 0.9412, 0.9569, 0.9412],\n",
       "          [0.9333, 0.9373, 0.9333,  ..., 0.9373, 0.9569, 0.9412]],\n",
       " \n",
       "         [[0.7255, 0.6549, 0.7137,  ..., 0.9373, 0.9373, 0.9412],\n",
       "          [0.6706, 0.6392, 0.6902,  ..., 0.9373, 0.9373, 0.9412],\n",
       "          [0.6275, 0.6392, 0.6745,  ..., 0.9373, 0.9373, 0.9412],\n",
       "          ...,\n",
       "          [0.9294, 0.9333, 0.9216,  ..., 0.9373, 0.9451, 0.9333],\n",
       "          [0.9529, 0.9451, 0.9216,  ..., 0.9333, 0.9490, 0.9333],\n",
       "          [0.9490, 0.9529, 0.9490,  ..., 0.9294, 0.9490, 0.9333]],\n",
       " \n",
       "         [[0.8353, 0.7529, 0.7961,  ..., 0.9451, 0.9451, 0.9490],\n",
       "          [0.7804, 0.7373, 0.7725,  ..., 0.9451, 0.9451, 0.9490],\n",
       "          [0.7255, 0.7373, 0.7569,  ..., 0.9451, 0.9451, 0.9490],\n",
       "          ...,\n",
       "          [0.9451, 0.9490, 0.9373,  ..., 0.9490, 0.9490, 0.9373],\n",
       "          [0.9569, 0.9490, 0.9255,  ..., 0.9451, 0.9529, 0.9373],\n",
       "          [0.9529, 0.9569, 0.9451,  ..., 0.9412, 0.9529, 0.9373]]]),\n",
       " tensor([ 0.3896,  0.3837,  0.3837,  ...,  0.8423, -0.6116, -0.5707]),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(20))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "from utils.Aggregation_Utils import *\n",
    "import pandas as pd\n",
    "import os \n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "\n",
    "class TileDataset(Dataset):\n",
    "    def __init__(self,df_path,tile_path,ext,trainmode,transform):\n",
    "        \"\"\"Custom Dataset for Feature Extractor Finetuning for Survival Analysis \n",
    "\n",
    "        Args:\n",
    "            df_path (str): Path to Dataframe which contains meta data and genomic data \n",
    "            tilepath (str): path to folder which contains subfolders with tiles(subfolder names must ne slide id)\n",
    "            ext (str): file extension of tiles(eg jpg or png)\n",
    "            trainmode (Bool): To generate train set or test set \n",
    "        \"\"\"\n",
    "        super(TileDataset,self).__init__()\n",
    "        #Genomic Tensor and Meta Dataframe\n",
    "        df = pd.read_csv(df_path) \n",
    "\n",
    "        assert trainmode in [\"train\",\"test\",\"val\"], \"Dataset mode not known\"\n",
    "        df[df[\"traintest\"]==(0 if trainmode==\"train\" else 1 if trainmode==\"test\" else 2)]\n",
    "        \n",
    "            \n",
    "        self.genomics_tensor = torch.Tensor(df[df.keys()[11:]].to_numpy()).to(torch.float32)\n",
    "        self.df_meta = df[[\"slide_id\",\"survival_months_discretized\",\"censorship\",\"survival_months\"]]\n",
    "        \n",
    "        # Tile Data Frame\n",
    "        file_list = []\n",
    "        root_list = []\n",
    "        for root, dirs, files in os.walk(tile_path, topdown=False):\n",
    "            for name in files:\n",
    "                file_list.append(os.path.join(root, name))\n",
    "                root_list.append(root.split(\"/\")[-1]+\".svs\")\n",
    "\n",
    "\n",
    "        df_tiles = pd.DataFrame({\"tilepath\":file_list,\"slide_id\":root_list},)\n",
    "        df_tiles = df_tiles[df_tiles[\"tilepath\"].str.endswith(ext)]\n",
    "        \n",
    "        # add slide_id to index mapping\n",
    "        diction= dict([(name,idx) for idx,name in enumerate(self.df_meta[\"slide_id\"]) ]) \n",
    "        df_tiles.insert(2,\"slideid_idx\",df_tiles[\"slide_id\"].map(diction))\n",
    "        df_tiles = df_tiles.dropna()\n",
    "        df_tiles.slideid_idx = df_tiles.slideid_idx.astype(int)\n",
    "        self.df_tiles = df_tiles\n",
    "        \n",
    "        # TODO transforms \n",
    "        self.transforms = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df_tiles)\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        tile_path,_,slide_idx = self.df_tiles.iloc[idx]\n",
    "        tile = Image.open(tile_path)\n",
    "        tile = self.transforms(tile)\n",
    "        \n",
    "        label = torch.tensor(self.df_meta.iloc[slide_idx, 1]).type(torch.int64)\n",
    "        censorship = torch.tensor(self.df_meta.iloc[slide_idx, 2]).type(torch.int64)\n",
    "        label_cont = torch.tensor(self.df_meta.iloc[slide_idx,3]).type(torch.int64)\n",
    "        return tile, self.genomics_tensor[slide_idx], censorship, label,label_cont\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "df_path_train = \"/work4/seibel/PORPOISE/datasets_csv/tcga_brca__4bins_trainsplit.csv\"\n",
    "df_path_test = \"/work4/seibel/PORPOISE/datasets_csv/tcga_brca__4bins_testsplit.csv\"\n",
    "\n",
    "tilepath = \"/work4/seibel/data/TCGA-BRCA-TILES/\"\n",
    "ext = \"jpg\"\n",
    "\n",
    "trainmode=\"train\"\n",
    "\n",
    "\n",
    "DS = TileDataset(df_path_train,tilepath,ext,trainmode,transform=transforms.ToTensor())\n",
    "DS.__getitem__(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.Tile_Dataset import TileDataset\n",
    "from torchvision import transforms\n",
    "import os \n",
    "df_path_train =\"/nodes/bevog/work4/seibel/PORPOISE/datasets_csv/tcga_brca__4bins_trainsplit.csv\"\n",
    "assert os.path.exists(df_path_train)\n",
    "tile_path =\"/nodes/bevog/work4/seibel/data/TCGA-BRCA-TILES/\"\n",
    "ext = \"jpg\"\n",
    "batch_size = 32\n",
    "transform_train=transforms.PILToTensor()\n",
    "train_set = TileDataset(df_path=df_path_train,tile_path=tile_path,ext=ext,trainmode = \"train\",transform=transform_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss \n",
    "The loss can be used from the previous colab notebook but has to be adapted to fully run on gpu \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seibel/.pyenv/versions/3.10.12/envs/env/lib/python3.10/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.8186)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.Aggregation_Utils import Survival_Loss\n",
    "import torch\n",
    "B = 10\n",
    "nbins  = 4 \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "#hist_tile,gen, censorship, label,label_cont = DS.__getitem__(8)\n",
    "\n",
    "criterion = Survival_Loss(0.2)\n",
    "prediction_logits = torch.rand(B,nbins,device=device)\n",
    "c  = torch.randint(0,2,size=(B,1),device=device)\n",
    "l = torch.randint(0,nbins,size=(B,),device=device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "criterion(prediction_logits,c,l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Starting with a smaller model to create a whole pytorch lightning module \n",
    "1. Resnet18\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "channels = 12\n",
    "model = nn.Sequential(nn.Conv2d(3, channels, kernel_size=(3, 3), padding='same', bias=True),\n",
    "                          nn.AdaptiveAvgPool2d(1),\n",
    "                          nn.Flatten(1),\n",
    "                          nn.Linear(channels,1),\n",
    "                          nn.Flatten(0))\n",
    "\n",
    "\n",
    "\n",
    "x = torch.rand((5,3,16,16))\n",
    "model(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import os\n",
    "f = \"./encoder_configs/base.yaml\"\n",
    "os.path.exists(f)\n",
    "with open(f, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "        \n",
    "print(config[\"train_settings\"][\"checkpoint_path\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF1 = ['case_id', 'slide_id', 'site', 'traintest', 'metas','gendata']\n",
    "DF2 = ['TILEPATH','SLIDE_ID']\n",
    "#get one tensor for gendata, one df with tilepath, metadata, tensoridx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"vali\"\n",
    "assert mode in [\"train\",\"test\",\"val\"], \"Dataset mode not known\"\n",
    "df_train.survival_months_discretized[df_train.survival_months_discretized==( 0 if mode==\"train\" else 1 if mode==\"test\" else 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len = 2\n",
    "train_len = 3\n",
    "diction = dict([(name,0) if idx<train_len else (name,1) if idx<train_len+test_len  else (name,2) for idx,name in enumerate([\"a\",\"b\",\"c\",\"d\",\"e\",\"f\"])])\n",
    "diction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
